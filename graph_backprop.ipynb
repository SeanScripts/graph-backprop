{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GraphNet:\n",
    "    # Make an empty graph on n nodes with linear activation\n",
    "    def __init__(self, n):\n",
    "        self.size = n\n",
    "        self.adj = np.zeros((n, n))\n",
    "        self.weights = np.zeros((n, n))\n",
    "        self.act = np.asarray(['linear' for i in range(self.size)])\n",
    "        self.input_nodes = np.asarray([0]) # Default\n",
    "        self.output_nodes = np.asarray([n-1]) # Default\n",
    "        #self.tempstates = [np.zeros(self.size)] # Needs to be dynamically resized\n",
    "        #self.states = [np.zeros(self.size)] # Needs to be dynamically resized\n",
    "        #self.mode = 'overwrite'\n",
    "        #self.time = 0\n",
    "    \n",
    "    # Sets the mode for the step method\n",
    "    # Options: overwrite, add\n",
    "    def mode(self, m):\n",
    "        self.mode = m\n",
    "    \n",
    "    # Connect an edge from node i to node j\n",
    "    def connect(self, i, j):\n",
    "        self.adj[i,j] = 1\n",
    "    \n",
    "    # Connect a list of nodes in a sequential loop\n",
    "    def connect_loop(self, v):\n",
    "        for i in range(len(v)):\n",
    "            self.adj[v[i], v[(i+1)%len(v)]] = 1\n",
    "    \n",
    "    # Connect in a clique, other than self-connections\n",
    "    def connect_complete(self, v):\n",
    "        for i in range(len(v)):\n",
    "            for j in range(len(v)):\n",
    "                if i == j:\n",
    "                    continue\n",
    "                self.adj[v[i], v[j]] = 1\n",
    "    \n",
    "    # Change activation on node i\n",
    "    # Options: linear, relu, sigmoid/logistic, tanh\n",
    "    def activation(self, i, f):\n",
    "        self.act[i] = f\n",
    "    \n",
    "    # Change activations on a list of nodes\n",
    "    def activations(self, v, f):\n",
    "        for i in range(len(v)):\n",
    "            self.act[v[i]] = f\n",
    "    \n",
    "    # Get the list of node indices for inputs to node i\n",
    "    def inputs(self, i):\n",
    "        return np.nonzero(self.adj[:,i])[0] # Returns a tuple even on a 1D array\n",
    "    \n",
    "    # Get the list of node indices for outputs from node i\n",
    "    def outputs(self, i):\n",
    "        return np.nonzero(self.adj[i,:])[0] # Returns a tuple even on a 1D array\n",
    "    \n",
    "    # Reset weights\n",
    "    def reset_weights(self):\n",
    "        self.weights = np.copy(self.adj)\n",
    "        self.reset_state() # No reason to save the state if the weights were reset.\n",
    "    \n",
    "    # Initialize random edge weights, assuming edge weights are all 0 or 1\n",
    "    def init_random(self):\n",
    "        self.weights = np.random.normal(size=(self.size, self.size)) * self.adj\n",
    "    \n",
    "    # Normalize rows to satisfy Markov state transition rules\n",
    "    def init_markov(self):\n",
    "        self.weights = np.random.random((self.size, self.size)) * self.adj\n",
    "        rowsums = np.sum(self.weights, axis=1, keepdims=True)\n",
    "        rowsums[rowsums == 0] = 1 # Prevent division by zero when normalizing the columns\n",
    "        self.weights = self.weights/rowsums\n",
    "    \n",
    "    def init_uniform(self):\n",
    "        self.weights = np.copy(self.adj)\n",
    "    \n",
    "    # Make the vector of indices be the input nodes\n",
    "    def define_input(self, v):\n",
    "        self.input_nodes = v\n",
    "    \n",
    "    # Make the vector of indices be the output nodes\n",
    "    def define_output(self, v):\n",
    "        self.output_nodes = v\n",
    "        \n",
    "    # numpy activation functions\n",
    "    # could be static, but meh\n",
    "    def relu(self, x):\n",
    "        return x * (x > 0)\n",
    "    \n",
    "    def sigmoid(self, x):\n",
    "        return 1.0/(1.0+np.exp(-x))\n",
    "    \n",
    "    def tanh(self, x):\n",
    "        return (np.exp(2*x) - 1)/(np.exp(2*x) + 1)\n",
    "    \n",
    "    # TODO: Redesign the steps so that multiple steps are done and the array of states is optionally returned,\n",
    "    # so that it doesn't modify the state variable every time it runs the network.\n",
    "    # This will allow for greater thread concurrency.\n",
    "    \n",
    "    # Combine all the old step functions\n",
    "    # Length of the output is n+1 because of the initial state of 0\n",
    "    def step(self, input_vals, n, weights = None):\n",
    "        temp_weights = self.weights\n",
    "        if weights is not None:\n",
    "            temp_weights = weights\n",
    "        x_states = [np.zeros(self.size)]\n",
    "        z_states = [np.zeros(self.size)]\n",
    "        input_vals = np.array(input_vals)\n",
    "        \n",
    "        for t in range(n):\n",
    "            input_state = np.zeros(self.size)\n",
    "            if input_vals.ndim == 1 and t == 0:\n",
    "                # Single value input\n",
    "                input_state[self.input_nodes] = input_vals\n",
    "            elif input_vals.ndim == 2:\n",
    "                # Sequence input\n",
    "                if t < input_vals.shape[0]:\n",
    "                    input_state[self.input_nodes] = input_vals[t]\n",
    "\n",
    "            # Bias neurons need to be activated before the step\n",
    "            input_state[self.act == 'bias'] = 1\n",
    "            \n",
    "            # This feels like it could be really bad.\n",
    "            # This makes it *absolutely mandatory* that there are no connections feeding into the input neurons.\n",
    "            z_states[-1] += input_state\n",
    "\n",
    "            # Activation functions are not run on the input nodes prior to entering the network.\n",
    "            # Preprocessing should take care of that anyway.\n",
    "            # So the inputs are considered the z state for their respective neurons.\n",
    "            # The x states on those neurons are all zero, but it doesn't really matter, \n",
    "            # since they can't come up in the backprop anyway.\n",
    "            \n",
    "            # Weighted sum of inputs (always adding the input state in)\n",
    "            new_x_state = z_states[-1] @ temp_weights\n",
    "            \n",
    "            # Apply activation functions to update the state (temporary states are stored for backprop)\n",
    "            new_z_state = np.copy(new_x_state)\n",
    "\n",
    "            # Applying activation functions in separate sets for each neuron that has a given one\n",
    "            new_z_state[self.act == 'relu'] = self.relu(new_z_state[self.act == 'relu'])\n",
    "            # This is kind of dumb, but initializing with 'linear' means numpy will cut off the string 'sigmoid'\n",
    "            new_z_state[self.act == 'sigma'] = self.sigmoid(new_z_state[self.act == 'sigma']) \n",
    "            new_z_state[self.act == 'tanh'] = self.tanh(new_z_state[self.act == 'tanh'])\n",
    "            \n",
    "            x_states.append(new_x_state)\n",
    "            z_states.append(new_z_state)\n",
    "        return np.array(x_states), np.array(z_states)\n",
    "    \n",
    "    # Simple function to get cleaner output\n",
    "    def get_output(self, input_vals, n_steps, seq_len=1):\n",
    "        x, z = self.step(input_vals, n_steps)\n",
    "        return z[-seq_len:][:, self.output_nodes]\n",
    "    \n",
    "    # Old code for reference\n",
    "    \"\"\"\n",
    "    \n",
    "    # Reset state\n",
    "    def reset_state(self):\n",
    "        self.states = [np.zeros(self.size)]\n",
    "        self.tempstates = [np.zeros(self.size)]\n",
    "    \n",
    "    # Runs one time step of the network, with the given input values, and returns the current output values\n",
    "    def step(self, input_vals):\n",
    "        self.time += 1\n",
    "        # tempstate = [self.states[-1][i] for i in range(self.size)]\n",
    "        # Edit the inputs of the last state. This will make things consistent, so each step is a single state\n",
    "        if self.mode == 'overwrite':\n",
    "            for i in range(len(self.input_nodes)):\n",
    "                self.states[-1][self.input_nodes] = input_vals\n",
    "        if self.mode == 'add':\n",
    "            for i in range(len(self.input_nodes)):\n",
    "                self.states[-1][self.input_nodes] += input_vals\n",
    "        \n",
    "        # Bias neurons need to be activated before the step\n",
    "        self.states[-1][self.act == 'bias'] = 1\n",
    "        \n",
    "        # Weighted sum of inputs\n",
    "        tempstate = self.states[-1] @ self.weights\n",
    "        \n",
    "        # Apply activation functions to update the state (temporary states are stored for backprop)\n",
    "        state = np.copy(tempstate)\n",
    "        \n",
    "        # Applying activation functions in separate sets for each neuron that has a given one\n",
    "        state[self.act == 'relu'] = self.relu(state[self.act == 'relu'])\n",
    "        # This is kind of dumb, but initializing with 'linear' means numpy will cut off the string 'sigmoid'\n",
    "        state[self.act == 'sigma'] = self.sigmoid(state[self.act == 'sigma']) \n",
    "        state[self.act == 'tanh'] = self.tanh(state[self.act == 'tanh'])\n",
    "        \n",
    "        output_vals = state[self.output_nodes]\n",
    "        self.tempstates.append(tempstate)\n",
    "        self.states.append(state)\n",
    "        return output_vals\n",
    "    \n",
    "    # Runs several time steps of the network, with the given vector of input value vectors at each time step, \n",
    "    # and returns a vector of output values\n",
    "    def steps(self, input_vals_v, n=1):\n",
    "        output_vals_v = np.zeros((n, len(self.input_nodes)))\n",
    "        empty_input = np.zeros(len(self.input_nodes))\n",
    "        for t in range(max(n, len(input_vals_v))):\n",
    "            input_vals = empty_input\n",
    "            if t < len(input_vals_v):\n",
    "                input_vals = input_vals_v[t]\n",
    "            output_vals_v[t] = self.step(input_vals)\n",
    "        return output_vals_v\n",
    "    \n",
    "    # Run n steps on a input only at initial step\n",
    "    def stepn(self, input_vals_0, n=1, reset=True):\n",
    "        if reset:\n",
    "            self.reset_state()\n",
    "        output_vals_v = np.zeros((n, len(self.output_nodes)))\n",
    "        empty_input = np.zeros(len(self.input_nodes))\n",
    "        for t in range(n):\n",
    "            input_vals = empty_input\n",
    "            if t == 0:\n",
    "                input_vals = input_vals_0\n",
    "            output_vals_v[t] = self.step(input_vals)\n",
    "        return output_vals_v\n",
    "    \n",
    "    # Run as many steps as necessary until you get a nonzero output \n",
    "    # (Obviously not a great thing to run if you have any sigmoid activations)\n",
    "    def stepv(self, input_vals_0, reset=True, max_step=100, verbose=True):\n",
    "        if reset:\n",
    "            self.reset_state()\n",
    "        output_vals = np.zeros(len(self.output_nodes))\n",
    "        empty_input = np.zeros(len(self.input_nodes))\n",
    "        t = 0\n",
    "        while t < max_step and np.count_nonzero(output_vals) == 0:\n",
    "            input_vals = empty_input\n",
    "            if t == 0:\n",
    "                input_vals = input_vals_0\n",
    "            output_vals = self.step(input_vals)\n",
    "            t += 1\n",
    "        if t == max_step:\n",
    "            print(\"Max step reached!\")\n",
    "        if verbose:\n",
    "            print(t)\n",
    "        return output_vals\n",
    "    \"\"\"\n",
    "    \n",
    "    # Combine all the old error functions (for MSE)\n",
    "    # Error calculation must be separate for backprop, because we don't want to run through the steps multiple times.\n",
    "    # So this is just for model evaluation (for a particular training example)\n",
    "    def get_loss(self, input_sequence, label_sequence, delay, weights=None):\n",
    "        using_weights = False\n",
    "        temp_weights = None\n",
    "        if weights is not None:\n",
    "            using_weights = True\n",
    "            temp_weights = weights\n",
    "        seq_len = 1\n",
    "        steps = delay\n",
    "        label_sequence = np.array(label_sequence)\n",
    "        if label_sequence.ndim == 2:\n",
    "            seq_len = label_sequence.shape[0]\n",
    "            steps = delay + seq_len - 1\n",
    "        x_states, z_states = self.step(input_sequence, steps, temp_weights if using_weights else None)\n",
    "        outputs = z_states[-seq_len:, self.output_nodes]\n",
    "        error = np.sum(np.subtract(outputs, label_sequence)**2)\n",
    "        return 0.5*error # 1/2 sum (z-y)^2\n",
    "    \n",
    "    # Old code for reference\n",
    "    \"\"\"\n",
    "    # Waits until the first nonzero output value and uses that as the real output\n",
    "    def error_first(self, train_vals, label_vals, max_step=100):\n",
    "        self.reset_state()\n",
    "        output_vals = np.zeros(len(self.output_nodes))\n",
    "        empty_input = np.zeros(len(self.input_nodes))\n",
    "        t = 0\n",
    "        while t < max_step and np.count_nonzero(output_vals) == 0:\n",
    "            input_vals = empty_input\n",
    "            if t == 0:\n",
    "                input_vals = train_vals\n",
    "            output_vals = self.step(input_vals)\n",
    "            t += 1\n",
    "        if t == max_step:\n",
    "            print(\"Max step reached!\")\n",
    "        err_v = np.subtract(output_vals, label_vals)\n",
    "        return err_v\n",
    "    \n",
    "    # Waits a fixed delay\n",
    "    def error_delay(self, train_vals, label_vals, delay, reset=True, max_step=100):\n",
    "        if reset:\n",
    "            self.reset_state()\n",
    "        output_vals = np.zeros(len(self.output_nodes))\n",
    "        empty_input = np.zeros(len(self.input_nodes))\n",
    "        t = 0\n",
    "        while t < delay:\n",
    "            input_vals = empty_input\n",
    "            if t == 0:\n",
    "                input_vals = train_vals\n",
    "            output_vals = self.step(input_vals)\n",
    "            t += 1\n",
    "        if t == max_step:\n",
    "            print(\"Max step reached!\")\n",
    "        err_v = np.subtract(output_vals, label_vals)\n",
    "        return err_v\n",
    "    \n",
    "    # Delay is until the label sequence starts.\n",
    "    # Training sequence can be any length, but should be a 2D array\n",
    "    def error_sequence(self, train_seq, label_seq, delay=1, reset=True):\n",
    "        if reset:\n",
    "            self.reset_state()\n",
    "        output_seq = np.zeros((len(label_seq), len(self.output_nodes)))\n",
    "        empty_input = np.zeros(len(self.input_nodes))\n",
    "        t = 0\n",
    "        while t < delay+len(label_seq)-1:\n",
    "            input_vals = empty_input\n",
    "            if t < len(train_seq):\n",
    "                input_vals = train_seq[t]\n",
    "            if t < delay-1:\n",
    "                self.step(input_vals)\n",
    "            else:\n",
    "                output_seq[t-delay+1] = self.step(input_vals)\n",
    "            t += 1\n",
    "        #print(output_seq)\n",
    "        #print(label_seq)\n",
    "        err_v = np.subtract(output_seq, label_seq)\n",
    "        #print('Err_v: '+str(err_v))\n",
    "        return err_v\n",
    "    \n",
    "    # Mean square error of training batch. train_x and train_y are batches of training data\n",
    "    # If delay = 0, first nonzero output will be used, otherwise there will be a fixed delay before the output is sampled\n",
    "    def mse_batch(self, train_x, train_y, delay=0, reset=True, max_step=100):\n",
    "        data_type = 'fixed'\n",
    "        if np.asarray(train_x).ndim == 3:\n",
    "            data_type = 'sequence'\n",
    "        mse = 0\n",
    "        # Should be able to parallelize over training examples\n",
    "        # However, I should use a different version of the stepping for this so it doesn't modify the state variable\n",
    "        for k in range(len(train_x)):\n",
    "            if data_type == 'fixed':\n",
    "                if delay == 0:\n",
    "                    mse += np.sum(self.error_first(train_x[k], train_y[k], max_step)**2)\n",
    "                else:\n",
    "                    mse += np.sum(self.error_delay(train_x[k], train_y[k], delay, reset, max_step)**2)\n",
    "            elif data_type == 'sequence':\n",
    "                val = self.error_sequence(train_x[k], train_y[k], delay, reset)\n",
    "                #print('Err: '+str(val))\n",
    "                mse += sum(val**2)\n",
    "        mse /= 2*len(train_x) # Factor of 1/2 for the coefficient of 2 on the derivative to cancel, as usual...\n",
    "        return mse\n",
    "        \"\"\"\n",
    "    \n",
    "    def derivative_relu(self, x):\n",
    "        return 1 * (x > 0)\n",
    "    \n",
    "    # Note that this uses Z instead of X\n",
    "    def derivative_sigmoid(self, z):\n",
    "        return z * (1 - z)\n",
    "    \n",
    "    def derivative_tanh(self, x):\n",
    "        return 4/(np.exp(x) + np.exp(-x))**2\n",
    "    \n",
    "    def derivative_activation(self, X, Z, t):\n",
    "        V = np.ones(self.size)\n",
    "        #V[self.act == 'linear'] = 1\n",
    "        V[self.act == 'bias'] = 0\n",
    "        V[self.act == 'relu'] = self.derivative_relu(X[t][self.act == 'relu'])\n",
    "        V[self.act == 'sigma'] = self.derivative_sigmoid(Z[t][self.act == 'sigma']) \n",
    "        V[self.act == 'tanh'] = self.derivative_tanh(X[t][self.act == 'tanh'])\n",
    "        return V\n",
    "    \n",
    "    def backprop(self, input_sequence, label_sequence, delay, debug=False):\n",
    "        # Calculate the required number of steps using the delay and the length of the label sequence\n",
    "        # If the label sequence is not two-dimensional, then it's just a single output value\n",
    "        seq_len = 1\n",
    "        steps = delay\n",
    "        label_sequence = np.array(label_sequence)\n",
    "        if label_sequence.ndim == 2:\n",
    "            seq_len = label_sequence.shape[0]\n",
    "            steps = delay + seq_len - 1\n",
    "        # Outputs at each time step before and after applying activation functions\n",
    "        X, Z = self.step(input_sequence, steps)\n",
    "        # Output labels\n",
    "        Y = np.zeros((seq_len, self.size))\n",
    "        Y[:, self.output_nodes] = label_sequence\n",
    "        # X and Z are steps x size\n",
    "        # Y is seq_len x size\n",
    "        # Square error\n",
    "        E = np.sum((Z[-seq_len:, self.output_nodes] - label_sequence)**2)\n",
    "        # Masking values\n",
    "        M = np.zeros(self.size)\n",
    "        M[self.output_nodes] = 1\n",
    "        # Alias to make things easier to keep track of...\n",
    "        W = self.weights\n",
    "        #if debug:\n",
    "        #    print('W', '\\n'+str(W))\n",
    "        # Going to be dividing by weights, but throw them out entirely if they are zero\n",
    "        # Turns out the bug was that the values are uninitialized when the where argument is used.\n",
    "        # Easy enough to fix. I still think it's weird that the result depended on whether the array was printed or not.\n",
    "        W_recip = np.zeros_like(W)\n",
    "        np.reciprocal(W, out=W_recip, where=(W != 0))\n",
    "        if debug:\n",
    "            print('W recip', '\\n'+str(W_recip))\n",
    "        # Time delay\n",
    "        T = delay\n",
    "        # Column of 1s to perform broadcasting before a dot product\n",
    "        C = np.ones((self.size, 1))\n",
    "        # The gradient for each weight in the adjacency matrix\n",
    "        D = np.zeros((self.size, self.size))\n",
    "        for S in range(0, seq_len):\n",
    "            # Path concatenation matrix: Weights times activations (applied to X, at various time steps)\n",
    "            B_final = W * self.derivative_activation(X, Z, T+S)\n",
    "            if debug:\n",
    "                print('B at', T+S, '\\n'+str(B_final))\n",
    "            # First order term is relatively simple\n",
    "            first_order = Z[(T+S-1):(T+S)].T * W_recip * (Z[(T+S):(T+S+1)] - Y[S:(S+1)]) * M * B_final\n",
    "            if debug:\n",
    "                print('first order', '\\n'+str(first_order))\n",
    "            D += first_order\n",
    "            B_prod = B_final.copy()\n",
    "            for N in range(1, T+S):\n",
    "                # Pre-multiply by the previous time's path concatenation matrix\n",
    "                B_prev = W * self.derivative_activation(X, Z, T+S-N)\n",
    "                if debug:\n",
    "                    print('B at', T+S-N, '\\n'+str(B_prev))\n",
    "                # Calculate the next order, lining up the matrix product to get a sum over outputs\n",
    "                next_order = Z[(T+S-N-1):(T+S-N)].T * W_recip * B_prev * ((C @ (Z[(T+S):(T+S+1)] - Y[S:(S+1)]) * M) @ B_prod.T)\n",
    "                if debug:\n",
    "                    print('next order', '\\n'+str(next_order))\n",
    "                D += next_order\n",
    "                B_prod = B_prev @ B_prod\n",
    "                if debug:\n",
    "                    print('B_prod', '\\n'+str(B_prod))\n",
    "        # This gradient is calculated for one training example over enough time steps to reach time zero\n",
    "        if debug:\n",
    "            print('D', '\\n'+str(D))\n",
    "        return D, E\n",
    "    \n",
    "    # Example to make sure this makes sense\n",
    "    # T = 1, seq_len = 1\n",
    "    # S = 0, B_1 first\n",
    "    # Z[0:1].T / W * (Z[1:2] - Y[0:1]) * M * B_1\n",
    "    # N loop doesn't activate\n",
    "    #\n",
    "    # T = 2, seq_len = 1\n",
    "    # S = 0, B_2 first\n",
    "    # Z[1:2].T / W * (Z[2:3] - Y[0:1]) * M * B_2\n",
    "    # Z[0:1].T / W * (C @ ((Z[2:3] - Y[0:1]) * M) @ (B_1 @ B2).T)\n",
    "    \n",
    "    # Old code for reference\n",
    "    \"\"\"\n",
    "    # Numpifying this seems difficult, with 4 nested for loops...\n",
    "    # I'm also not entirely sure this is correct. Models trained with it seem to reach the local minimum correctly, though.\n",
    "    def backprop(self, train_vals, label_vals, delay=1, verbose=False):\n",
    "        # Initialize with zero matrix of derivatives for each weight\n",
    "        dw = np.zeros((self.size, self.size))\n",
    "        # Calculate error function\n",
    "        # E = 1/2 (observed - expected)**2\n",
    "        err_v = [[0 for i in range(len(self.output_nodes))]] #Initialize to empty array for each output node\n",
    "        if len(np.asarray(label_vals).shape) == 1:\n",
    "            err_v = [self.error_delay(train_vals, label_vals, delay)] # Row vector, one time step\n",
    "        if len(np.asarray(label_vals).shape) == 2:\n",
    "            err_v = self.error_sequence(train_vals, label_vals, delay=delay) # 2D, rows are time steps\n",
    "        # Look at each time step\n",
    "        for dt in range(len(err_v)):\n",
    "            nodes_i = [self.output_nodes[i] for i in range(len(self.output_nodes))]\n",
    "            nodes_d = [err_v[len(err_v)-1-dt][i] for i in range(len(self.output_nodes))]\n",
    "            newnodes_i = []\n",
    "            newnodes_d = []\n",
    "            # dE/dw = (observed - expected) * d(observed)/dw\n",
    "            for k in range(1, len(self.states)-dt): # Or max step size, maybe? \n",
    "                #print('Paths:', len(nodes_i), \"\\t dt:\", dt, \"\\t k:\", k)\n",
    "                for i in range(len(nodes_i)):\n",
    "                    # node value = activation( weighted sum of input values )\n",
    "                    # d node value / dw = activation'( weighted sum of input values ) * d (weighted sum of input values) / dw\n",
    "                    node_val = self.states[len(self.states)-k-dt][nodes_i[i]]\n",
    "                    node_sum = self.tempstates[len(self.states)-k-dt][nodes_i[i]]\n",
    "                    act_deriv = 1\n",
    "                    #if self.act[nodes_i[i]] == 'linear':\n",
    "                    #    do nothing\n",
    "                    if self.act[nodes_i[i]] == 'relu' and node_sum < 0:\n",
    "                        act_deriv = 0\n",
    "                    if self.act[nodes_i[i]] == 'sigma':\n",
    "                        act_deriv = node_val * (1 - node_val)\n",
    "                    if self.act[nodes_i[i]] == 'tanh':\n",
    "                        act_deriv = 4.0/(math.exp(node_sum)+math.exp(-node_sum))**2\n",
    "                    #print(\"nodes_i[i]\", nodes_i[i])\n",
    "                    in_nodes_i = self.inputs(nodes_i[i])\n",
    "                    #print(\"in_nodes_i\", in_nodes_i)\n",
    "                    for j in range(len(in_nodes_i)):\n",
    "                        # Self-weights are covered just fine when nodes_i[i] = in_nodes_i[j]\n",
    "                        in_node_val = self.states[len(self.states)-(k+1)-dt][in_nodes_i[j]]\n",
    "                        # d (weighted sum of input values) / dw = input value [...for w in these weights]\n",
    "                        dweight = nodes_d[i] * act_deriv * in_node_val\n",
    "                        # Add this to the total derivative with respect to this weight\n",
    "                        dw[nodes_i[i], in_nodes_i[j]] += dweight\n",
    "                        if verbose:\n",
    "                            print(dw)\n",
    "                        # nodes_d stores the buildup of chained derivatives\n",
    "                        weight = self.weights[nodes_i[i], in_nodes_i[j]]\n",
    "                        # d (weighted sum of input values) / dw = ... * weight * d node value / dw\n",
    "                        #print(in_nodes_i, in_nodes_i[j], newnodes_i)\n",
    "                        if in_nodes_i[j] in newnodes_i:\n",
    "                            index = newnodes_i.index(in_nodes_i[j])\n",
    "                            newnodes_d[index] += nodes_d[i] * act_deriv * weight\n",
    "                        else:\n",
    "                            #print(newnodes_i, in_nodes_i[j])\n",
    "                            newnodes_i.append(in_nodes_i[j])\n",
    "                            newnodes_d.append( nodes_d[i] * act_deriv * weight )\n",
    "                nodes_i = newnodes_i\n",
    "                nodes_d = newnodes_d\n",
    "                newnodes_i = []\n",
    "                newnodes_d = []\n",
    "        return dw\n",
    "    \"\"\"\n",
    "    \n",
    "    # Manually check to see if the gradients line up with what the backprop function gives\n",
    "    def gradient_check(self, input_sequence, label_sequence, delay, epsilon):\n",
    "        backprop_gradient = self.backprop(input_sequence, label_sequence, delay)[0]\n",
    "        manual_gradient = np.zeros((self.size, self.size))\n",
    "        base_err = self.get_loss(input_sequence, label_sequence, delay)\n",
    "        for i in range(self.size):\n",
    "            for j in range(self.size):\n",
    "                if self.weights[i, j] == 0:\n",
    "                    continue\n",
    "                dw = np.zeros((self.size, self.size))\n",
    "                dw[i, j] = epsilon\n",
    "                grad = (self.get_loss(input_sequence, label_sequence, delay, self.weights + dw) - base_err)/epsilon\n",
    "                manual_gradient[i, j] = grad\n",
    "        print('Backprop-calculated gradient:')\n",
    "        print(backprop_gradient)\n",
    "        print('Manually-calculated gradient:')\n",
    "        print(manual_gradient)\n",
    "        print('Difference:')\n",
    "        print(backprop_gradient-manual_gradient)\n",
    "    \n",
    "    # Uses the whole dataset as the batches\n",
    "    def train(self, train_x, train_y, delay, epochs, learning_rate):\n",
    "        errors = []\n",
    "        for ep in range(epochs):\n",
    "            avg_D = np.zeros((self.size, self.size))\n",
    "            avg_E = 0\n",
    "            for k in range(len(train_x)):\n",
    "                D, E = self.backprop(train_x[k], train_y[k], delay)\n",
    "                avg_D += D\n",
    "                avg_E += E\n",
    "            avg_D /= len(train_x)\n",
    "            avg_E /= len(train_x)\n",
    "            #print(avg_D)\n",
    "            #print(avg_E)\n",
    "            self.weights += - learning_rate * avg_D\n",
    "            # Evaluate error to see how we're doing.\n",
    "            errors.append(avg_E)\n",
    "        print(self.weights)\n",
    "        return errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 0.]])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = GraphNet(3)\n",
    "test.connect(0,1)\n",
    "test.connect(1,2)\n",
    "test.activations([1,2], 'sigma')\n",
    "test.init_markov()\n",
    "test.weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.weights *= 0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, z = test.step([1], 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.         0.         0.        ]\n",
      " [0.         0.9        0.        ]\n",
      " [0.         0.         0.63985455]]\n",
      "[[1.         0.         0.        ]\n",
      " [0.         0.7109495  0.5       ]\n",
      " [0.         0.5        0.65472058]]\n"
     ]
    }
   ],
   "source": [
    "print(x)\n",
    "print(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W recip \n",
      "[[0.         1.11111111 0.        ]\n",
      " [0.         0.         1.11111111]\n",
      " [0.         0.         0.        ]]\n",
      "B at 2 \n",
      "[[0.         0.225      0.        ]\n",
      " [0.         0.         0.20345539]\n",
      " [0.         0.         0.        ]]\n",
      "first order \n",
      "[[ 0.          0.         -0.        ]\n",
      " [ 0.          0.         -0.05549274]\n",
      " [ 0.          0.         -0.        ]]\n",
      "B at 1 \n",
      "[[0.         0.18495028 0.        ]\n",
      " [0.         0.         0.225     ]\n",
      " [0.         0.         0.        ]]\n",
      "next order \n",
      "[[ 0.         -0.01443618  0.        ]\n",
      " [ 0.         -0.          0.        ]\n",
      " [ 0.         -0.          0.        ]]\n",
      "B_prod \n",
      "[[0.         0.         0.03762913]\n",
      " [0.         0.         0.        ]\n",
      " [0.         0.         0.        ]]\n",
      "D \n",
      "[[ 0.         -0.01443618  0.        ]\n",
      " [ 0.          0.         -0.05549274]\n",
      " [ 0.          0.          0.        ]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([[ 0.        , -0.01443618,  0.        ],\n",
       "        [ 0.        ,  0.        , -0.05549274],\n",
       "        [ 0.        ,  0.        ,  0.        ]]), 0.11921787702676306)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.backprop([[1]], [[1]], 2, debug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backprop-calculated gradient:\n",
      "[[ 0.         -0.01401536  0.        ]\n",
      " [ 0.          0.         -0.05211305]\n",
      " [ 0.          0.          0.        ]]\n",
      "Manually-calculated gradient:\n",
      "[[ 0.         -0.01401535  0.        ]\n",
      " [ 0.          0.         -0.05211303]\n",
      " [ 0.          0.          0.        ]]\n",
      "Difference:\n",
      "[[ 0.00000000e+00 -4.62332528e-09  0.00000000e+00]\n",
      " [ 0.00000000e+00  0.00000000e+00 -1.94988543e-08]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00]]\n"
     ]
    }
   ],
   "source": [
    "test.gradient_check([[1]], [[1]], 2, epsilon=0.000001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear = GraphNet(3)\n",
    "linear.connect(0,2)\n",
    "linear.connect(1,2)\n",
    "linear.activation(1, 'bias')\n",
    "linear.define_input([0])\n",
    "linear.define_output([2])\n",
    "linear.init_markov() # Makes it really be slope and intercept 1 to begin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x20348de6438>"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "scatter = 0.1\n",
    "slope = 0.5\n",
    "intercept = 2\n",
    "# Uniformly scattered points off a line\n",
    "train_lin_x = [[-5 + 0.1*i + scatter*(-1+2*random.random())] for i in range(100)]\n",
    "train_lin_y = [[intercept + slope*(-5+0.1*i) + scatter*(-1+2*random.random())] for i in range(100)]\n",
    "plt.scatter(train_lin_x, train_lin_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0., 0., 0.],\n",
       "        [0., 0., 1.]]), array([[0., 1., 0.],\n",
       "        [0., 0., 1.]]))"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear.step([0], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.         0.         0.50088902]\n",
      " [0.         0.         1.9985163 ]\n",
      " [0.         0.         0.        ]]\n"
     ]
    }
   ],
   "source": [
    "# Estimated slope and intercept are present in the weights of the trained network\n",
    "errs = linear.train(train_lin_x, train_lin_y, delay=1, epochs=100, learning_rate=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x20348e86f60>]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Seems to work decently well\n",
    "plt.plot(errs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backprop-calculated gradient:\n",
      "[[ 0.          0.          0.61411253]\n",
      " [ 0.          0.         -0.12059935]\n",
      " [ 0.          0.          0.        ]]\n",
      "Manually-calculated gradient:\n",
      "[[ 0.          0.          0.6141255 ]\n",
      " [ 0.          0.         -0.12059885]\n",
      " [ 0.          0.          0.        ]]\n",
      "Difference:\n",
      "[[ 0.00000000e+00  0.00000000e+00 -1.29650873e-05]\n",
      " [ 0.00000000e+00  0.00000000e+00 -5.00009668e-07]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00]]\n"
     ]
    }
   ],
   "source": [
    "linear.gradient_check(train_lin_x[0], train_lin_y[0], delay=1, epsilon=0.000001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing a regular NN as a graph\n",
    "xor_net = GraphNet(6)\n",
    "xor_net.define_input([0,1])\n",
    "xor_net.connect(0,3)\n",
    "xor_net.connect(0,4)\n",
    "xor_net.connect(1,3)\n",
    "xor_net.connect(1,4)\n",
    "xor_net.connect(2,3)\n",
    "xor_net.connect(2,4)\n",
    "xor_net.connect(2,5)\n",
    "xor_net.connect(3,5)\n",
    "xor_net.connect(4,5)\n",
    "xor_net.activation(2, 'bias')\n",
    "xor_net.activations([3,4,5], 'sigma')\n",
    "xor_net.init_random()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.          0.          0.          5.22530668  4.8404654   0.        ]\n",
      " [-0.         -0.         -0.         -5.25229404 -4.59368784 -0.        ]\n",
      " [-0.         -0.         -0.         -2.96056489  2.27544543  3.13892944]\n",
      " [ 0.          0.         -0.          0.         -0.          7.13463366]\n",
      " [ 0.          0.          0.         -0.          0.         -6.81103931]\n",
      " [ 0.          0.          0.          0.          0.         -0.        ]]\n"
     ]
    }
   ],
   "source": [
    "train_x = [[0,0], [0,1], [1,0], [1,1]]\n",
    "train_y = [[0], [1], [1], [0]]\n",
    "errs_xor = xor_net.train(train_x, train_y, delay=2, epochs=5000, learning_rate=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x20348f08e10>]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(errs_xor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([[ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "         0.        ],\n",
      "       [ 0.        ,  0.        ,  0.        , -2.96056489,  2.27544543,\n",
      "         3.13892944],\n",
      "       [ 0.        ,  0.        ,  0.        , -2.96056489,  2.27544543,\n",
      "        -2.68617093]]), array([[0.        , 0.        , 1.        , 0.        , 0.        ,\n",
      "        0.        ],\n",
      "       [0.        , 0.        , 1.        , 0.04923955, 0.90682292,\n",
      "        0.95847029],\n",
      "       [0.        , 0.        , 0.        , 0.04923955, 0.90682292,\n",
      "        0.06379433]]))\n",
      "(array([[ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "         0.        ],\n",
      "       [ 0.        ,  0.        ,  0.        , -8.21285894, -2.31824241,\n",
      "         3.13892944],\n",
      "       [ 0.        ,  0.        ,  0.        , -2.98755226,  2.52222298,\n",
      "         2.53043521]]), array([[0.00000000e+00, 1.00000000e+00, 1.00000000e+00, 0.00000000e+00,\n",
      "        0.00000000e+00, 0.00000000e+00],\n",
      "       [1.00000000e+00, 1.00000000e+00, 1.00000000e+00, 2.71070928e-04,\n",
      "        8.96233593e-02, 9.58470288e-01],\n",
      "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 4.79913993e-02,\n",
      "        9.25685124e-01, 9.26248089e-01]]))\n",
      "(array([[ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "         0.        ],\n",
      "       [ 0.        ,  0.        ,  0.        ,  2.26474179,  7.11591083,\n",
      "         3.13892944],\n",
      "       [ 0.        ,  0.        ,  0.        , -2.96056489,  2.27544543,\n",
      "         2.79678533]]), array([[1.        , 0.        , 1.        , 0.        , 0.        ,\n",
      "        0.        ],\n",
      "       [0.        , 0.        , 1.        , 0.90591457, 0.99918858,\n",
      "        0.95847029],\n",
      "       [0.        , 0.        , 0.        , 0.04923955, 0.90682292,\n",
      "        0.94250186]]))\n",
      "(array([[ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "         0.        ],\n",
      "       [ 0.        ,  0.        ,  0.        , -2.98755226,  2.52222298,\n",
      "         3.13892944],\n",
      "       [ 0.        ,  0.        ,  0.        , -2.98755226,  2.52222298,\n",
      "        -2.82354727]]), array([[1.        , 1.        , 1.        , 0.        , 0.        ,\n",
      "        0.        ],\n",
      "       [1.        , 1.        , 1.        , 0.0479914 , 0.92568512,\n",
      "        0.95847029],\n",
      "       [0.        , 0.        , 0.        , 0.0479914 , 0.92568512,\n",
      "        0.05606491]]))\n"
     ]
    }
   ],
   "source": [
    "# This is pretty much unreadable lol\n",
    "print(xor_net.step([0,0], 2))\n",
    "print(xor_net.step([0,1], 2))\n",
    "print(xor_net.step([1,0], 2))\n",
    "print(xor_net.step([1,1], 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backprop-calculated gradient:\n",
      "[[ 0.          0.          0.         -0.00092767 -0.00137299  0.        ]\n",
      " [ 0.          0.          0.          0.00095742  0.00140962  0.        ]\n",
      " [ 0.          0.          0.          0.00033519 -0.00076588 -0.00137699]\n",
      " [ 0.          0.          0.          0.          0.         -0.00249415]\n",
      " [ 0.          0.          0.          0.          0.          0.00263667]\n",
      " [ 0.          0.          0.          0.          0.          0.        ]]\n",
      "Manually-calculated gradient:\n",
      "[[ 0.          0.          0.         -0.00092767 -0.00137299  0.        ]\n",
      " [ 0.          0.          0.          0.00095742  0.00140962  0.        ]\n",
      " [ 0.          0.          0.          0.00033519 -0.00076588 -0.00137698]\n",
      " [ 0.          0.          0.          0.          0.         -0.00249414]\n",
      " [ 0.          0.          0.          0.          0.          0.00263668]\n",
      " [ 0.          0.          0.          0.          0.          0.        ]]\n",
      "Difference:\n",
      "[[ 0.00000000e+00  0.00000000e+00  0.00000000e+00 -2.54833334e-09\n",
      "  -1.18065015e-09  0.00000000e+00]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00 -7.09427558e-10\n",
      "  -3.71760311e-09  0.00000000e+00]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00 -3.48917124e-09\n",
      "  -5.74141203e-09 -1.34886290e-08]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00 -2.34718579e-09]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00 -8.03362798e-09]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00]]\n"
     ]
    }
   ],
   "source": [
    "xor_net.gradient_check(train_x, train_y, delay=2, epsilon=0.000001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "bpcheck = GraphNet(8)\n",
    "bpcheck.define_input([0,1])\n",
    "bpcheck.define_output([6,7])\n",
    "bpcheck.connect(0,2)\n",
    "bpcheck.connect(1,2)\n",
    "bpcheck.connect_loop([2,3,4,5])\n",
    "bpcheck.connect(4,6)\n",
    "bpcheck.connect(4,7)\n",
    "#bpcheck.init_random()\n",
    "bpcheck.init_uniform()\n",
    "# Square loop with two inputs and outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [1. 1.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [1. 1.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [1. 1.]]\n",
      "[[0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [1. 1.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [1. 1.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [1. 1.]]\n"
     ]
    }
   ],
   "source": [
    "# Make sure regular stepping works\n",
    "#print(bpcheck.step([0,1]))\n",
    "#print(bpcheck.step([0,0]))\n",
    "#print(bpcheck.step([0,0]))\n",
    "#print(bpcheck.step([0,0]))\n",
    "# Make sure multiple stepping works\n",
    "#bpcheck.reset_state()\n",
    "print(bpcheck.get_output([0,1], 12, 12))\n",
    "print(bpcheck.get_output([1,0], 12, 12))\n",
    "# These are the same, as expected. Bug fixed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. ],\n",
       "        [0. , 0. , 1. , 0. , 0. , 0. , 0. , 0. ],\n",
       "        [0. , 0. , 0. , 2. , 0. , 0. , 0. , 0. ],\n",
       "        [0. , 0. , 0. , 0. , 2. , 0. , 0. , 0. ],\n",
       "        [0. , 0. , 0. , 0. , 0. , 1. , 0.5, 0.5],\n",
       "        [0. , 0. , 1. , 0. , 0. , 0. , 0. , 0. ],\n",
       "        [0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. ],\n",
       "        [0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. ]]), 0.5)"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bpcheck.backprop([[0,1]], [[1,1], [0,0], [0,0], [0,0], [0.5,0.5]], delay=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.         0.         1.         0.         0.         0.\n",
      "  0.         0.        ]\n",
      " [0.         0.         1.11742165 0.         0.         0.\n",
      "  0.         0.        ]\n",
      " [0.         0.         0.         0.91886753 0.         0.\n",
      "  0.         0.        ]\n",
      " [0.         0.         0.         0.         0.91886753 0.\n",
      "  0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.76954337\n",
      "  1.0599282  1.0599282 ]\n",
      " [0.         0.         0.76954337 0.         0.         0.\n",
      "  0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.        ]]\n"
     ]
    }
   ],
   "source": [
    "train_x = [[[0,1]]]\n",
    "train_y = [[[1,1], [0,0], [0,0], [0,0], [0.5,0.5]]]\n",
    "errs_bpc = bpcheck.train(train_x, train_y, delay=4, epochs=200, learning_rate=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x20349372f60>]"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(errs_bpc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.50000155, 0.50000155],\n",
       "       [0.        , 0.        ],\n",
       "       [0.        , 0.        ],\n",
       "       [0.        , 0.        ],\n",
       "       [0.25000193, 0.25000193]])"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Trained perfectly\n",
    "bpcheck.get_output([0,1], 12, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "fc = GraphNet(7)\n",
    "fc.connect(0,1)\n",
    "fc.connect_complete([1,2,3,4,5])\n",
    "fc.connect(5,6)\n",
    "#fc.activation(6, 'sigma')\n",
    "fc.init_markov()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x2034904d240>]"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(fc.get_output([1], 20, 20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[ 0.        , -0.02285141,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        , -0.04698958, -0.05082877, -0.04699833,\n",
       "         -0.05913729,  0.        ],\n",
       "        [ 0.        , -0.02796992,  0.        , -0.03240219, -0.02809855,\n",
       "         -0.04159034,  0.        ],\n",
       "        [ 0.        , -0.03067392, -0.03088159,  0.        , -0.03081258,\n",
       "         -0.04663744,  0.        ],\n",
       "        [ 0.        , -0.02969746, -0.02992878, -0.0346864 ,  0.        ,\n",
       "         -0.04481153,  0.        ],\n",
       "        [ 0.        , -0.03052507, -0.03075028, -0.03598602, -0.0306719 ,\n",
       "          0.        , -0.17626287],\n",
       "        [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ]]), 0.9537496630970231)"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fc.backprop([[1]], [[1]], delay=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backprop-calculated gradient:\n",
      "[[ 0.         -0.02285141  0.          0.          0.          0.\n",
      "   0.        ]\n",
      " [ 0.          0.         -0.04698958 -0.05082877 -0.04699833 -0.05913729\n",
      "   0.        ]\n",
      " [ 0.         -0.02796992  0.         -0.03240219 -0.02809855 -0.04159034\n",
      "   0.        ]\n",
      " [ 0.         -0.03067392 -0.03088159  0.         -0.03081258 -0.04663744\n",
      "   0.        ]\n",
      " [ 0.         -0.02969746 -0.02992878 -0.0346864   0.         -0.04481153\n",
      "   0.        ]\n",
      " [ 0.         -0.03052507 -0.03075028 -0.03598602 -0.0306719   0.\n",
      "  -0.17626287]\n",
      " [ 0.          0.          0.          0.          0.          0.\n",
      "   0.        ]]\n",
      "Manually-calculated gradient:\n",
      "[[ 0.         -0.02285141  0.          0.          0.          0.\n",
      "   0.        ]\n",
      " [ 0.          0.         -0.04698987 -0.05082919 -0.04699863 -0.05913776\n",
      "   0.        ]\n",
      " [ 0.         -0.02797004  0.         -0.0324023  -0.02809867 -0.04159059\n",
      "   0.        ]\n",
      " [ 0.         -0.03067403 -0.03088172  0.         -0.0308127  -0.04663773\n",
      "   0.        ]\n",
      " [ 0.         -0.02969757 -0.0299289  -0.03468653  0.         -0.04481185\n",
      "   0.        ]\n",
      " [ 0.         -0.03052517 -0.03075038 -0.03598625 -0.030672    0.\n",
      "  -0.17626271]\n",
      " [ 0.          0.          0.          0.          0.          0.\n",
      "   0.        ]]\n",
      "Difference:\n",
      "[[ 0.00000000e+00 -2.73874741e-09  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
      " [ 0.00000000e+00  0.00000000e+00  2.86380083e-07  4.20379332e-07\n",
      "   3.00812213e-07  4.77794720e-07  0.00000000e+00]\n",
      " [ 0.00000000e+00  1.12917637e-07  0.00000000e+00  1.16262633e-07\n",
      "   1.13231946e-07  2.44081333e-07  0.00000000e+00]\n",
      " [ 0.00000000e+00  1.15958485e-07  1.28865193e-07  0.00000000e+00\n",
      "   1.19652994e-07  2.93160413e-07  0.00000000e+00]\n",
      " [ 0.00000000e+00  1.15246435e-07  1.24715841e-07  1.28939577e-07\n",
      "   0.00000000e+00  3.14105164e-07  0.00000000e+00]\n",
      " [ 0.00000000e+00  9.62568699e-08  9.95819898e-08  2.28243830e-07\n",
      "   9.90817508e-08  0.00000000e+00 -1.62883688e-07]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00]]\n"
     ]
    }
   ],
   "source": [
    "fc.gradient_check([[1]], [[1]], delay=10, epsilon=0.00001)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
