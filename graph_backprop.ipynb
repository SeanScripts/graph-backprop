{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GraphNet:\n",
    "    # Make an empty graph on n nodes with linear activation\n",
    "    def __init__(self, n):\n",
    "        self.size = n\n",
    "        self.adj = np.zeros((n, n))\n",
    "        self.weights = np.zeros((n, n))\n",
    "        self.act = np.asarray(['linear' for i in range(self.size)])\n",
    "        self.input_nodes = np.asarray([0]) # Default\n",
    "        self.output_nodes = np.asarray([n-1]) # Default\n",
    "        #self.tempstates = [np.zeros(self.size)] # Needs to be dynamically resized\n",
    "        #self.states = [np.zeros(self.size)] # Needs to be dynamically resized\n",
    "        #self.mode = 'overwrite'\n",
    "        #self.time = 0\n",
    "    \n",
    "    # Sets the mode for the step method\n",
    "    # Options: overwrite, add\n",
    "    def mode(self, m):\n",
    "        self.mode = m\n",
    "    \n",
    "    # Connect an edge from node i to node j\n",
    "    def connect(self, i, j):\n",
    "        self.adj[i,j] = 1\n",
    "    \n",
    "    # Connect a list of nodes in a sequential loop\n",
    "    def connect_loop(self, v):\n",
    "        for i in range(len(v)):\n",
    "            self.adj[v[i], v[(i+1)%len(v)]] = 1\n",
    "    \n",
    "    # Connect in a clique, other than self-connections\n",
    "    def connect_complete(self, v):\n",
    "        for i in range(len(v)):\n",
    "            for j in range(len(v)):\n",
    "                if i == j:\n",
    "                    continue\n",
    "                self.adj[v[i], v[j]] = 1\n",
    "    \n",
    "    # Change activation on node i\n",
    "    # Options: linear, relu, sigmoid/logistic, tanh\n",
    "    def activation(self, i, f):\n",
    "        self.act[i] = f\n",
    "    \n",
    "    # Change activations on a list of nodes\n",
    "    def activations(self, v, f):\n",
    "        for i in range(len(v)):\n",
    "            self.act[v[i]] = f\n",
    "    \n",
    "    # Get the list of node indices for inputs to node i\n",
    "    def inputs(self, i):\n",
    "        return np.nonzero(self.adj[:,i])[0] # Returns a tuple even on a 1D array\n",
    "    \n",
    "    # Get the list of node indices for outputs from node i\n",
    "    def outputs(self, i):\n",
    "        return np.nonzero(self.adj[i,:])[0] # Returns a tuple even on a 1D array\n",
    "    \n",
    "    # Reset weights\n",
    "    def reset_weights(self):\n",
    "        self.weights = np.copy(self.adj)\n",
    "        self.reset_state() # No reason to save the state if the weights were reset.\n",
    "    \n",
    "    # Initialize random edge weights, assuming edge weights are all 0 or 1\n",
    "    def init_random(self):\n",
    "        self.weights = np.random.normal(size=(self.size, self.size)) * self.adj\n",
    "    \n",
    "    # Normalize rows to satisfy Markov state transition rules\n",
    "    def init_markov(self):\n",
    "        self.weights = np.random.random((self.size, self.size)) * self.adj\n",
    "        rowsums = np.sum(self.weights, axis=1, keepdims=True)\n",
    "        rowsums[rowsums == 0] = 1 # Prevent division by zero when normalizing the columns\n",
    "        self.weights = self.weights/rowsums\n",
    "    \n",
    "    def init_uniform(self):\n",
    "        self.weights = np.copy(self.adj)\n",
    "    \n",
    "    # Make the vector of indices be the input nodes\n",
    "    def define_input(self, v):\n",
    "        self.input_nodes = v\n",
    "    \n",
    "    # Make the vector of indices be the output nodes\n",
    "    def define_output(self, v):\n",
    "        self.output_nodes = v\n",
    "        \n",
    "    # numpy activation functions\n",
    "    # could be static, but meh\n",
    "    def relu(self, x):\n",
    "        return x * (x > 0)\n",
    "    \n",
    "    def sigmoid(self, x):\n",
    "        return 1.0/(1.0+np.exp(-x))\n",
    "    \n",
    "    def tanh(self, x):\n",
    "        return (np.exp(2*x) - 1)/(np.exp(2*x) + 1)\n",
    "    \n",
    "    # TODO: Redesign the steps so that multiple steps are done and the array of states is optionally returned,\n",
    "    # so that it doesn't modify the state variable every time it runs the network.\n",
    "    # This will allow for greater thread concurrency.\n",
    "    \n",
    "    # Combine all the old step functions\n",
    "    # Length of the output is n+1 because of the initial state of 0\n",
    "    def step(self, input_vals, n):\n",
    "        x_states = [np.zeros(self.size)]\n",
    "        z_states = [np.zeros(self.size)]\n",
    "        input_vals = np.array(input_vals)\n",
    "        \n",
    "        for t in range(n):\n",
    "            input_state = np.zeros(self.size)\n",
    "            if input_vals.ndim == 1 and t == 0:\n",
    "                # Single value input\n",
    "                input_state[self.input_nodes] = input_vals\n",
    "            else:\n",
    "                # Sequence input\n",
    "                if t < input_vals.shape[0]:\n",
    "                    input_state[self.input_nodes] = input_vals[t]\n",
    "\n",
    "            # Bias neurons need to be activated before the step\n",
    "            input_state[self.act == 'bias'] = 1\n",
    "            \n",
    "            # This feels like it could be really bad.\n",
    "            # This makes it *absolutely mandatory* that there are no connections feeding into the input neurons.\n",
    "            z_states[-1] += input_state\n",
    "\n",
    "            # Activation functions are not run on the input nodes prior to entering the network.\n",
    "            # Preprocessing should take care of that anyway.\n",
    "            # So the inputs are considered the z state for their respective neurons.\n",
    "            # The x states on those neurons are all zero, but it doesn't really matter, \n",
    "            # since they can't come up in the backprop anyway.\n",
    "\n",
    "            # Weighted sum of inputs (always adding the input state in)\n",
    "            new_x_state = z_states[-1] @ self.weights\n",
    "\n",
    "            # Apply activation functions to update the state (temporary states are stored for backprop)\n",
    "            new_z_state = np.copy(new_x_state)\n",
    "\n",
    "            # Applying activation functions in separate sets for each neuron that has a given one\n",
    "            new_z_state[self.act == 'relu'] = self.relu(new_z_state[self.act == 'relu'])\n",
    "            # This is kind of dumb, but initializing with 'linear' means numpy will cut off the string 'sigmoid'\n",
    "            new_z_state[self.act == 'sigma'] = self.sigmoid(new_z_state[self.act == 'sigma']) \n",
    "            new_z_state[self.act == 'tanh'] = self.tanh(new_z_state[self.act == 'tanh'])\n",
    "\n",
    "            x_states.append(new_x_state)\n",
    "            z_states.append(new_z_state)\n",
    "        return np.array(x_states), np.array(z_states)\n",
    "    \n",
    "    # Old code for reference\n",
    "    \"\"\"\n",
    "    \n",
    "    # Reset state\n",
    "    def reset_state(self):\n",
    "        self.states = [np.zeros(self.size)]\n",
    "        self.tempstates = [np.zeros(self.size)]\n",
    "    \n",
    "    # Runs one time step of the network, with the given input values, and returns the current output values\n",
    "    def step(self, input_vals):\n",
    "        self.time += 1\n",
    "        # tempstate = [self.states[-1][i] for i in range(self.size)]\n",
    "        # Edit the inputs of the last state. This will make things consistent, so each step is a single state\n",
    "        if self.mode == 'overwrite':\n",
    "            for i in range(len(self.input_nodes)):\n",
    "                self.states[-1][self.input_nodes] = input_vals\n",
    "        if self.mode == 'add':\n",
    "            for i in range(len(self.input_nodes)):\n",
    "                self.states[-1][self.input_nodes] += input_vals\n",
    "        \n",
    "        # Bias neurons need to be activated before the step\n",
    "        self.states[-1][self.act == 'bias'] = 1\n",
    "        \n",
    "        # Weighted sum of inputs\n",
    "        tempstate = self.states[-1] @ self.weights\n",
    "        \n",
    "        # Apply activation functions to update the state (temporary states are stored for backprop)\n",
    "        state = np.copy(tempstate)\n",
    "        \n",
    "        # Applying activation functions in separate sets for each neuron that has a given one\n",
    "        state[self.act == 'relu'] = self.relu(state[self.act == 'relu'])\n",
    "        # This is kind of dumb, but initializing with 'linear' means numpy will cut off the string 'sigmoid'\n",
    "        state[self.act == 'sigma'] = self.sigmoid(state[self.act == 'sigma']) \n",
    "        state[self.act == 'tanh'] = self.tanh(state[self.act == 'tanh'])\n",
    "        \n",
    "        output_vals = state[self.output_nodes]\n",
    "        self.tempstates.append(tempstate)\n",
    "        self.states.append(state)\n",
    "        return output_vals\n",
    "    \n",
    "    # Runs several time steps of the network, with the given vector of input value vectors at each time step, \n",
    "    # and returns a vector of output values\n",
    "    def steps(self, input_vals_v, n=1):\n",
    "        output_vals_v = np.zeros((n, len(self.input_nodes)))\n",
    "        empty_input = np.zeros(len(self.input_nodes))\n",
    "        for t in range(max(n, len(input_vals_v))):\n",
    "            input_vals = empty_input\n",
    "            if t < len(input_vals_v):\n",
    "                input_vals = input_vals_v[t]\n",
    "            output_vals_v[t] = self.step(input_vals)\n",
    "        return output_vals_v\n",
    "    \n",
    "    # Run n steps on a input only at initial step\n",
    "    def stepn(self, input_vals_0, n=1, reset=True):\n",
    "        if reset:\n",
    "            self.reset_state()\n",
    "        output_vals_v = np.zeros((n, len(self.output_nodes)))\n",
    "        empty_input = np.zeros(len(self.input_nodes))\n",
    "        for t in range(n):\n",
    "            input_vals = empty_input\n",
    "            if t == 0:\n",
    "                input_vals = input_vals_0\n",
    "            output_vals_v[t] = self.step(input_vals)\n",
    "        return output_vals_v\n",
    "    \n",
    "    # Run as many steps as necessary until you get a nonzero output \n",
    "    # (Obviously not a great thing to run if you have any sigmoid activations)\n",
    "    def stepv(self, input_vals_0, reset=True, max_step=100, verbose=True):\n",
    "        if reset:\n",
    "            self.reset_state()\n",
    "        output_vals = np.zeros(len(self.output_nodes))\n",
    "        empty_input = np.zeros(len(self.input_nodes))\n",
    "        t = 0\n",
    "        while t < max_step and np.count_nonzero(output_vals) == 0:\n",
    "            input_vals = empty_input\n",
    "            if t == 0:\n",
    "                input_vals = input_vals_0\n",
    "            output_vals = self.step(input_vals)\n",
    "            t += 1\n",
    "        if t == max_step:\n",
    "            print(\"Max step reached!\")\n",
    "        if verbose:\n",
    "            print(t)\n",
    "        return output_vals\n",
    "    \"\"\"\n",
    "    \n",
    "    # Combine all the old error functions (for MSE)\n",
    "    # Error calculation must be separate for backprop, because we don't want to run through the steps multiple times.\n",
    "    # So this is just for model evaluation (for a particular training example)\n",
    "    def get_mse(self, input_sequence, label_sequence, delay):\n",
    "        seq_len = 1\n",
    "        steps = delay\n",
    "        label_sequence = np.array(label_sequence)\n",
    "        if label_sequence.ndim == 2:\n",
    "            seq_len = label_sequence.shape[0]\n",
    "            steps = delay + seq_len - 1\n",
    "        x_states, z_states = self.step(input_sequence, steps)\n",
    "        outputs = z_states[-seq_len:, self.output_nodes]\n",
    "        error = np.sum(np.subtract(outputs, label_sequence)**2)\n",
    "        return error\n",
    "    \n",
    "    # Old code for reference\n",
    "    \"\"\"\n",
    "    # Waits until the first nonzero output value and uses that as the real output\n",
    "    def error_first(self, train_vals, label_vals, max_step=100):\n",
    "        self.reset_state()\n",
    "        output_vals = np.zeros(len(self.output_nodes))\n",
    "        empty_input = np.zeros(len(self.input_nodes))\n",
    "        t = 0\n",
    "        while t < max_step and np.count_nonzero(output_vals) == 0:\n",
    "            input_vals = empty_input\n",
    "            if t == 0:\n",
    "                input_vals = train_vals\n",
    "            output_vals = self.step(input_vals)\n",
    "            t += 1\n",
    "        if t == max_step:\n",
    "            print(\"Max step reached!\")\n",
    "        err_v = np.subtract(output_vals, label_vals)\n",
    "        return err_v\n",
    "    \n",
    "    # Waits a fixed delay\n",
    "    def error_delay(self, train_vals, label_vals, delay, reset=True, max_step=100):\n",
    "        if reset:\n",
    "            self.reset_state()\n",
    "        output_vals = np.zeros(len(self.output_nodes))\n",
    "        empty_input = np.zeros(len(self.input_nodes))\n",
    "        t = 0\n",
    "        while t < delay:\n",
    "            input_vals = empty_input\n",
    "            if t == 0:\n",
    "                input_vals = train_vals\n",
    "            output_vals = self.step(input_vals)\n",
    "            t += 1\n",
    "        if t == max_step:\n",
    "            print(\"Max step reached!\")\n",
    "        err_v = np.subtract(output_vals, label_vals)\n",
    "        return err_v\n",
    "    \n",
    "    # Delay is until the label sequence starts.\n",
    "    # Training sequence can be any length, but should be a 2D array\n",
    "    def error_sequence(self, train_seq, label_seq, delay=1, reset=True):\n",
    "        if reset:\n",
    "            self.reset_state()\n",
    "        output_seq = np.zeros((len(label_seq), len(self.output_nodes)))\n",
    "        empty_input = np.zeros(len(self.input_nodes))\n",
    "        t = 0\n",
    "        while t < delay+len(label_seq)-1:\n",
    "            input_vals = empty_input\n",
    "            if t < len(train_seq):\n",
    "                input_vals = train_seq[t]\n",
    "            if t < delay-1:\n",
    "                self.step(input_vals)\n",
    "            else:\n",
    "                output_seq[t-delay+1] = self.step(input_vals)\n",
    "            t += 1\n",
    "        #print(output_seq)\n",
    "        #print(label_seq)\n",
    "        err_v = np.subtract(output_seq, label_seq)\n",
    "        #print('Err_v: '+str(err_v))\n",
    "        return err_v\n",
    "    \n",
    "    # Mean square error of training batch. train_x and train_y are batches of training data\n",
    "    # If delay = 0, first nonzero output will be used, otherwise there will be a fixed delay before the output is sampled\n",
    "    def mse_batch(self, train_x, train_y, delay=0, reset=True, max_step=100):\n",
    "        data_type = 'fixed'\n",
    "        if np.asarray(train_x).ndim == 3:\n",
    "            data_type = 'sequence'\n",
    "        mse = 0\n",
    "        # Should be able to parallelize over training examples\n",
    "        # However, I should use a different version of the stepping for this so it doesn't modify the state variable\n",
    "        for k in range(len(train_x)):\n",
    "            if data_type == 'fixed':\n",
    "                if delay == 0:\n",
    "                    mse += np.sum(self.error_first(train_x[k], train_y[k], max_step)**2)\n",
    "                else:\n",
    "                    mse += np.sum(self.error_delay(train_x[k], train_y[k], delay, reset, max_step)**2)\n",
    "            elif data_type == 'sequence':\n",
    "                val = self.error_sequence(train_x[k], train_y[k], delay, reset)\n",
    "                #print('Err: '+str(val))\n",
    "                mse += sum(val**2)\n",
    "        mse /= 2*len(train_x) # Factor of 1/2 for the coefficient of 2 on the derivative to cancel, as usual...\n",
    "        return mse\n",
    "        \"\"\"\n",
    "    \n",
    "    def derivative_relu(self, x):\n",
    "        return 1 * (x > 0)\n",
    "    \n",
    "    # Note that this uses Z instead of X\n",
    "    def derivative_sigmoid(self, z):\n",
    "        return z * (1 - z)\n",
    "    \n",
    "    def derivative_tanh(self, x):\n",
    "        return 4/(np.exp(x) + np.exp(-x))**2\n",
    "    \n",
    "    def derivative_activation(self, X, Z, t):\n",
    "        V = np.ones(self.size)\n",
    "        #V[self.act == 'linear'] = 1\n",
    "        V[self.act == 'bias'] = 0\n",
    "        V[self.act == 'relu'] = self.derivative_relu(X[t][self.act == 'relu'])\n",
    "        V[self.act == 'sigma'] = self.derivative_sigmoid(Z[t][self.act == 'sigma']) \n",
    "        V[self.act == 'tanh'] = self.derivative_tanh(X[t][self.act == 'tanh'])\n",
    "        return V\n",
    "    \n",
    "    def backprop(self, input_sequence, label_sequence, delay, debug=False):\n",
    "        # Calculate the required number of steps using the delay and the length of the label sequence\n",
    "        # If the label sequence is not two-dimensional, then it's just a single output value\n",
    "        seq_len = 1\n",
    "        steps = delay\n",
    "        label_sequence = np.array(label_sequence)\n",
    "        if label_sequence.ndim == 2:\n",
    "            seq_len = label_sequence.shape[0]\n",
    "            steps = delay + seq_len - 1\n",
    "        # Outputs at each time step before and after applying activation functions\n",
    "        X, Z = self.step(input_sequence, steps)\n",
    "        # Output labels\n",
    "        Y = np.zeros((seq_len, self.size))\n",
    "        Y[:, self.output_nodes] = label_sequence\n",
    "        # X and Z are steps x size\n",
    "        # Y is seq_len x size\n",
    "        # Square error\n",
    "        E = np.sum((Z[-seq_len:, self.output_nodes] - label_sequence)**2)\n",
    "        # Masking values\n",
    "        M = np.zeros(self.size)\n",
    "        M[self.output_nodes] = 1\n",
    "        # Alias to make things easier to keep track of...\n",
    "        W = self.weights\n",
    "        #if debug:\n",
    "        #    print('W', '\\n'+str(W))\n",
    "        # Going to be dividing by weights, but throw them out entirely if they are zero\n",
    "        # Turns out the bug was that the values are uninitialized when the where argument is used.\n",
    "        # Easy enough to fix. I still think it's weird that the result depended on whether the array was printed or not.\n",
    "        W_recip = np.zeros_like(W)\n",
    "        np.reciprocal(W, out=W_recip, where=(W != 0))\n",
    "        if debug:\n",
    "            print('W recip', '\\n'+str(W_recip))\n",
    "        # Time delay\n",
    "        T = delay\n",
    "        # Column of 1s to perform broadcasting before a dot product\n",
    "        C = np.ones((self.size, 1))\n",
    "        # The gradient for each weight in the adjacency matrix\n",
    "        D = np.zeros((self.size, self.size))\n",
    "        for S in range(0, seq_len):\n",
    "            # Path concatenation matrix: Weights times activations (applied to X, at various time steps)\n",
    "            B_0 = W * self.derivative_activation(X, Z, T+S)\n",
    "            if debug:\n",
    "                print('B at', T+S, '\\n'+str(B_0))\n",
    "            # First order term is relatively simple\n",
    "            first_order = Z[(T+S-1):(T+S)].T * W_recip * (Z[(T+S):(T+S+1)] - Y[S:(S+1)]) * M * B_0\n",
    "            if debug:\n",
    "                print('first order', '\\n'+str(first_order))\n",
    "            D += first_order\n",
    "            B_n = np.eye(self.size)\n",
    "            for N in range(1, T+S):\n",
    "                # Pre-multiply by the previous time's path concatenation matrix\n",
    "                B = W * self.derivative_activation(X, Z, T+S-N)\n",
    "                if debug:\n",
    "                    print('B at', T+S-N, '\\n'+str(B))\n",
    "                B_n = B @ B_n\n",
    "                if debug:\n",
    "                    print('B_n', '\\n'+str(B_n))\n",
    "                # Calculate the next order, lining up the matrix product to get a sum over outputs\n",
    "                next_order = Z[(T+S-N-1):(T+S-N)].T * W_recip * B_0 * ((C @ (Z[(T+S):(T+S+1)] - Y[S:(S+1)]) * M) @ B_n.T)\n",
    "                if debug:\n",
    "                    print('next order', '\\n'+str(next_order))\n",
    "                D += next_order\n",
    "        # This gradient is calculated for one training example over enough time steps to reach time zero\n",
    "        if debug:\n",
    "            print('D', '\\n'+str(D))\n",
    "        return D, E\n",
    "    \n",
    "    # Example to make sure this makes sense\n",
    "    # T = 1, seq_len = 1\n",
    "    # S = 0, B_1 first\n",
    "    # Z[0:1].T / W * (Z[1:2] - Y[0:1]) * M * B_1\n",
    "    # N loop doesn't activate\n",
    "    #\n",
    "    # T = 2, seq_len = 1\n",
    "    # S = 0, B_2 first\n",
    "    # Z[1:2].T / W * (Z[2:3] - Y[0:1]) * M * B_2\n",
    "    # Z[0:1].T / W * (C @ ((Z[2:3] - Y[0:1]) * M) @ (B_1 @ B2).T)\n",
    "    \n",
    "    # Old code for reference\n",
    "    \"\"\"\n",
    "    # Numpifying this seems difficult, with 4 nested for loops...\n",
    "    # I'm also not entirely sure this is correct. Models trained with it seem to reach the local minimum correctly, though.\n",
    "    def backprop(self, train_vals, label_vals, delay=1, verbose=False):\n",
    "        # Initialize with zero matrix of derivatives for each weight\n",
    "        dw = np.zeros((self.size, self.size))\n",
    "        # Calculate error function\n",
    "        # E = 1/2 (observed - expected)**2\n",
    "        err_v = [[0 for i in range(len(self.output_nodes))]] #Initialize to empty array for each output node\n",
    "        if len(np.asarray(label_vals).shape) == 1:\n",
    "            err_v = [self.error_delay(train_vals, label_vals, delay)] # Row vector, one time step\n",
    "        if len(np.asarray(label_vals).shape) == 2:\n",
    "            err_v = self.error_sequence(train_vals, label_vals, delay=delay) # 2D, rows are time steps\n",
    "        # Look at each time step\n",
    "        for dt in range(len(err_v)):\n",
    "            nodes_i = [self.output_nodes[i] for i in range(len(self.output_nodes))]\n",
    "            nodes_d = [err_v[len(err_v)-1-dt][i] for i in range(len(self.output_nodes))]\n",
    "            newnodes_i = []\n",
    "            newnodes_d = []\n",
    "            # dE/dw = (observed - expected) * d(observed)/dw\n",
    "            for k in range(1, len(self.states)-dt): # Or max step size, maybe? \n",
    "                #print('Paths:', len(nodes_i), \"\\t dt:\", dt, \"\\t k:\", k)\n",
    "                for i in range(len(nodes_i)):\n",
    "                    # node value = activation( weighted sum of input values )\n",
    "                    # d node value / dw = activation'( weighted sum of input values ) * d (weighted sum of input values) / dw\n",
    "                    node_val = self.states[len(self.states)-k-dt][nodes_i[i]]\n",
    "                    node_sum = self.tempstates[len(self.states)-k-dt][nodes_i[i]]\n",
    "                    act_deriv = 1\n",
    "                    #if self.act[nodes_i[i]] == 'linear':\n",
    "                    #    do nothing\n",
    "                    if self.act[nodes_i[i]] == 'relu' and node_sum < 0:\n",
    "                        act_deriv = 0\n",
    "                    if self.act[nodes_i[i]] == 'sigma':\n",
    "                        act_deriv = node_val * (1 - node_val)\n",
    "                    if self.act[nodes_i[i]] == 'tanh':\n",
    "                        act_deriv = 4.0/(math.exp(node_sum)+math.exp(-node_sum))**2\n",
    "                    #print(\"nodes_i[i]\", nodes_i[i])\n",
    "                    in_nodes_i = self.inputs(nodes_i[i])\n",
    "                    #print(\"in_nodes_i\", in_nodes_i)\n",
    "                    for j in range(len(in_nodes_i)):\n",
    "                        # Self-weights are covered just fine when nodes_i[i] = in_nodes_i[j]\n",
    "                        in_node_val = self.states[len(self.states)-(k+1)-dt][in_nodes_i[j]]\n",
    "                        # d (weighted sum of input values) / dw = input value [...for w in these weights]\n",
    "                        dweight = nodes_d[i] * act_deriv * in_node_val\n",
    "                        # Add this to the total derivative with respect to this weight\n",
    "                        dw[nodes_i[i], in_nodes_i[j]] += dweight\n",
    "                        if verbose:\n",
    "                            print(dw)\n",
    "                        # nodes_d stores the buildup of chained derivatives\n",
    "                        weight = self.weights[nodes_i[i], in_nodes_i[j]]\n",
    "                        # d (weighted sum of input values) / dw = ... * weight * d node value / dw\n",
    "                        #print(in_nodes_i, in_nodes_i[j], newnodes_i)\n",
    "                        if in_nodes_i[j] in newnodes_i:\n",
    "                            index = newnodes_i.index(in_nodes_i[j])\n",
    "                            newnodes_d[index] += nodes_d[i] * act_deriv * weight\n",
    "                        else:\n",
    "                            #print(newnodes_i, in_nodes_i[j])\n",
    "                            newnodes_i.append(in_nodes_i[j])\n",
    "                            newnodes_d.append( nodes_d[i] * act_deriv * weight )\n",
    "                nodes_i = newnodes_i\n",
    "                nodes_d = newnodes_d\n",
    "                newnodes_i = []\n",
    "                newnodes_d = []\n",
    "        return dw\n",
    "    \"\"\"\n",
    "    \n",
    "    # Uses the whole dataset as the batches\n",
    "    def train(self, train_x, train_y, delay, epochs, learning_rate):\n",
    "        errors = []\n",
    "        for ep in range(epochs):\n",
    "            avg_D = np.zeros((self.size, self.size))\n",
    "            avg_E = 0\n",
    "            for k in range(len(train_x)):\n",
    "                D, E = self.backprop(train_x[k], train_y[k], delay)\n",
    "                avg_D += D\n",
    "                avg_E += E\n",
    "            avg_D /= len(train_x)\n",
    "            avg_E /= len(train_x)\n",
    "            #print(avg_D)\n",
    "            #print(avg_E)\n",
    "            self.weights += - learning_rate * avg_D\n",
    "            # Evaluate error to see how we're doing.\n",
    "            errors.append(avg_E)\n",
    "        print(self.weights)\n",
    "        return errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 0.]])"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = GraphNet(3)\n",
    "test.connect(0,1)\n",
    "test.connect(1,2)\n",
    "test.init_markov()\n",
    "test.weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.weights *= 0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, z = test.step([1], 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]]\n",
      "[[1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]]\n"
     ]
    }
   ],
   "source": [
    "print(x)\n",
    "print(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 0.]])"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.reciprocal(test.weights, where=(test.weights!=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W recip \n",
      "[[0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 0.]]\n",
      "B at 2 \n",
      "[[0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 0.]]\n",
      "first order \n",
      "[[ 0.  0. -0.]\n",
      " [ 0.  0. -1.]\n",
      " [ 0.  0. -0.]]\n",
      "B at 1 \n",
      "[[0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 0.]]\n",
      "B_n \n",
      "[[0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 0.]]\n",
      "next order \n",
      "[[ 0. -1.  0.]\n",
      " [ 0. -0.  0.]\n",
      " [ 0. -0.  0.]]\n",
      "D \n",
      "[[ 0. -1.  0.]\n",
      " [ 0.  0. -1.]\n",
      " [ 0.  0.  0.]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 0., -1.,  0.],\n",
       "       [ 0.,  0., -1.],\n",
       "       [ 0.,  0.,  0.]])"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.backprop([[1]], [[2]], 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear = GraphNet(3)\n",
    "linear.connect(0,2)\n",
    "linear.connect(1,2)\n",
    "linear.activation(1, 'bias')\n",
    "linear.define_input([0])\n",
    "linear.define_output([2])\n",
    "linear.init_markov() # Makes it really be slope and intercept 1 to begin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x23f07761e80>"
      ]
     },
     "execution_count": 288,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "scatter = 0.1\n",
    "slope = 0.5\n",
    "intercept = 2\n",
    "# Uniformly scattered points off a line\n",
    "train_lin_x = [[-5 + 0.1*i + scatter*(-1+2*random.random())] for i in range(100)]\n",
    "train_lin_y = [[intercept + slope*(-5+0.1*i) + scatter*(-1+2*random.random())] for i in range(100)]\n",
    "plt.scatter(train_lin_x, train_lin_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0., 0., 0.],\n",
       "        [0., 0., 1.]]), array([[0., 1., 0.],\n",
       "        [0., 0., 1.]]))"
      ]
     },
     "execution_count": 263,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear.step([0], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.          0.          4.22543398]\n",
      " [ 0.          0.         -1.02819271]\n",
      " [ 0.          0.          0.        ]]\n",
      "3.1438797822611093\n",
      "[[ 0.          0.          0.68225695]\n",
      " [ 0.          0.         -0.90466366]\n",
      " [ 0.          0.          0.        ]]\n",
      "0.8714324941178788\n",
      "[[ 0.         0.         0.1065399]\n",
      " [ 0.         0.        -0.8108534]\n",
      " [ 0.         0.         0.       ]]\n",
      "0.6624196869344954\n",
      "[[ 0.          0.          0.01335529]\n",
      " [ 0.          0.         -0.72924589]\n",
      " [ 0.          0.          0.        ]]\n",
      "0.536262850234924\n",
      "[[ 0.          0.         -0.00140186]\n",
      " [ 0.          0.         -0.65625584]\n",
      " [ 0.          0.          0.        ]]\n",
      "0.4352097427936185\n",
      "[[ 0.          0.         -0.00344448]\n",
      " [ 0.          0.         -0.59063713]\n",
      " [ 0.          0.          0.        ]]\n",
      "0.35338098429330533\n",
      "[[ 0.          0.         -0.00345511]\n",
      " [ 0.          0.         -0.5315903 ]\n",
      " [ 0.          0.          0.        ]]\n",
      "0.28709568968085303\n",
      "[[ 0.          0.         -0.00316744]\n",
      " [ 0.          0.         -0.4784482 ]\n",
      " [ 0.          0.          0.        ]]\n",
      "0.23340073513381704\n",
      "[[ 0.          0.         -0.00286019]\n",
      " [ 0.          0.         -0.43061891]\n",
      " [ 0.          0.          0.        ]]\n",
      "0.1899046737939413\n",
      "[[ 0.          0.         -0.00257579]\n",
      " [ 0.          0.         -0.38757103]\n",
      " [ 0.          0.          0.        ]]\n",
      "0.15467031347955637\n",
      "[[ 0.          0.         -0.00231854]\n",
      " [ 0.          0.         -0.34882655]\n",
      " [ 0.          0.          0.        ]]\n",
      "0.12612841545420395\n",
      "[[ 0.          0.         -0.0020868 ]\n",
      " [ 0.          0.         -0.31395526]\n",
      " [ 0.          0.          0.        ]]\n",
      "0.10300780433393308\n",
      "[[ 0.          0.         -0.0018782 ]\n",
      " [ 0.          0.         -0.28256996]\n",
      " [ 0.          0.          0.        ]]\n",
      "0.08427875351537166\n",
      "[[ 0.          0.         -0.00169044]\n",
      " [ 0.          0.         -0.25432217]\n",
      " [ 0.          0.          0.        ]]\n",
      "0.06910712406580588\n",
      "[[ 0.          0.         -0.00152145]\n",
      " [ 0.          0.         -0.22889824]\n",
      " [ 0.          0.          0.        ]]\n",
      "0.056817214535163016\n",
      "[[ 0.          0.         -0.00136936]\n",
      " [ 0.          0.         -0.20601587]\n",
      " [ 0.          0.          0.        ]]\n",
      "0.04686166712521029\n",
      "[[ 0.          0.         -0.00123246]\n",
      " [ 0.          0.         -0.185421  ]\n",
      " [ 0.          0.          0.        ]]\n",
      "0.03879708992187985\n",
      "[[ 0.          0.         -0.00110926]\n",
      " [ 0.          0.         -0.16688494]\n",
      " [ 0.          0.          0.        ]]\n",
      "0.03226430947392002\n",
      "[[ 0.          0.         -0.00099837]\n",
      " [ 0.          0.         -0.15020188]\n",
      " [ 0.          0.          0.        ]]\n",
      "0.026972374223598074\n",
      "[[ 0.          0.         -0.00089856]\n",
      " [ 0.          0.         -0.13518659]\n",
      " [ 0.          0.          0.        ]]\n",
      "0.02268559634751842\n",
      "[[ 0.          0.         -0.00080874]\n",
      " [ 0.          0.         -0.12167233]\n",
      " [ 0.          0.          0.        ]]\n",
      "0.019213054887808056\n",
      "[[ 0.          0.         -0.00072789]\n",
      " [ 0.          0.         -0.10950906]\n",
      " [ 0.          0.          0.        ]]\n",
      "0.016400092672831955\n",
      "[[ 0.          0.         -0.00065512]\n",
      " [ 0.          0.         -0.09856172]\n",
      " [ 0.          0.          0.        ]]\n",
      "0.014121428324345481\n",
      "[[ 0.          0.         -0.00058963]\n",
      " [ 0.          0.         -0.08870876]\n",
      " [ 0.          0.          0.        ]]\n",
      "0.012275576579370171\n",
      "[[ 0.          0.         -0.00053069]\n",
      " [ 0.          0.         -0.07984078]\n",
      " [ 0.          0.          0.        ]]\n",
      "0.010780328423716392\n",
      "[[ 0.          0.         -0.00047764]\n",
      " [ 0.          0.         -0.0718593 ]\n",
      " [ 0.          0.          0.        ]]\n",
      "0.009569089735088158\n",
      "[[ 0.          0.         -0.00042989]\n",
      " [ 0.          0.         -0.06467571]\n",
      " [ 0.          0.          0.        ]]\n",
      "0.00858791536929308\n",
      "[[ 0.          0.         -0.00038691]\n",
      " [ 0.          0.         -0.05821025]\n",
      " [ 0.          0.          0.        ]]\n",
      "0.0077931065961489064\n",
      "[[ 0.          0.         -0.00034824]\n",
      " [ 0.          0.         -0.05239112]\n",
      " [ 0.          0.          0.        ]]\n",
      "0.007149264881679484\n",
      "[[ 0.          0.         -0.00031342]\n",
      " [ 0.          0.         -0.04715371]\n",
      " [ 0.          0.          0.        ]]\n",
      "0.006627715337565779\n",
      "[[ 0.          0.         -0.00028209]\n",
      " [ 0.          0.         -0.04243988]\n",
      " [ 0.          0.          0.        ]]\n",
      "0.006205229622750938\n",
      "[[ 0.          0.         -0.00025389]\n",
      " [ 0.          0.         -0.03819727]\n",
      " [ 0.          0.          0.        ]]\n",
      "0.005862991418850455\n",
      "[[ 0.          0.         -0.00022851]\n",
      " [ 0.          0.         -0.03437879]\n",
      " [ 0.          0.          0.        ]]\n",
      "0.0055857584045688365\n",
      "[[ 0.          0.         -0.00020567]\n",
      " [ 0.          0.         -0.03094203]\n",
      " [ 0.          0.          0.        ]]\n",
      "0.005361183405834877\n",
      "[[ 0.          0.         -0.00018511]\n",
      " [ 0.          0.         -0.02784884]\n",
      " [ 0.          0.          0.        ]]\n",
      "0.005179264487602681\n",
      "[[ 0.          0.         -0.0001666 ]\n",
      " [ 0.          0.         -0.02506486]\n",
      " [ 0.          0.          0.        ]]\n",
      "0.005031899495963626\n",
      "[[ 0.          0.         -0.00014995]\n",
      " [ 0.          0.         -0.02255919]\n",
      " [ 0.          0.          0.        ]]\n",
      "0.004912525211134928\n",
      "[[ 0.          0.         -0.00013496]\n",
      " [ 0.          0.         -0.02030401]\n",
      " [ 0.          0.          0.        ]]\n",
      "0.004815825040220072\n",
      "[[ 0.          0.         -0.00012147]\n",
      " [ 0.          0.         -0.01827427]\n",
      " [ 0.          0.          0.        ]]\n",
      "0.004737492231203611\n",
      "[[ 0.          0.         -0.00010932]\n",
      " [ 0.          0.         -0.01644744]\n",
      " [ 0.          0.          0.        ]]\n",
      "0.004674038062401659\n",
      "[[ 0.00000000e+00  0.00000000e+00 -9.83947223e-05]\n",
      " [ 0.00000000e+00  0.00000000e+00 -1.48032278e-02]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00]]\n",
      "0.0046226364646688375\n",
      "[[ 0.00000000e+00  0.00000000e+00 -8.85584555e-05]\n",
      " [ 0.00000000e+00  0.00000000e+00 -1.33233873e-02]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00]]\n",
      "0.004580998156274409\n",
      "[[ 0.00000000e+00  0.00000000e+00 -7.97054950e-05]\n",
      " [ 0.00000000e+00  0.00000000e+00 -1.19914826e-02]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00]]\n",
      "0.004547268684771206\n",
      "[[ 0.00000000e+00  0.00000000e+00 -7.17375421e-05]\n",
      " [ 0.00000000e+00  0.00000000e+00 -1.07927250e-02]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00]]\n",
      "0.004519945834930387\n",
      "[[ 0.00000000e+00  0.00000000e+00 -6.45661249e-05]\n",
      " [ 0.00000000e+00  0.00000000e+00 -9.71380407e-03]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00]]\n",
      "0.004497812724325547\n",
      "[[ 0.00000000e+00  0.00000000e+00 -5.81116159e-05]\n",
      " [ 0.00000000e+00  0.00000000e+00 -8.74274012e-03]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00]]\n",
      "0.004479883606832298\n",
      "[[ 0.00000000e+00  0.00000000e+00 -5.23023474e-05]\n",
      " [ 0.00000000e+00  0.00000000e+00 -7.86875092e-03]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00]]\n",
      "0.0044653599702849725\n",
      "[[ 0.00000000e+00  0.00000000e+00 -4.70738166e-05]\n",
      " [ 0.00000000e+00  0.00000000e+00 -7.08213218e-03]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00]]\n",
      "0.0044535949730039655\n",
      "[[ 0.00000000e+00  0.00000000e+00 -4.23679685e-05]\n",
      " [ 0.00000000e+00  0.00000000e+00 -6.37414968e-03]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00]]\n",
      "0.004444064635297491\n",
      "[[ 0.00000000e+00  0.00000000e+00 -3.81325519e-05]\n",
      " [ 0.00000000e+00  0.00000000e+00 -5.73694236e-03]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00]]\n",
      "0.004436344502888611\n",
      "[[ 0.00000000e+00  0.00000000e+00 -3.43205389e-05]\n",
      " [ 0.00000000e+00  0.00000000e+00 -5.16343502e-03]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00]]\n",
      "0.00443009074292268\n",
      "[[ 0.00000000e+00  0.00000000e+00 -3.08896031e-05]\n",
      " [ 0.00000000e+00  0.00000000e+00 -4.64725973e-03]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00]]\n",
      "0.004425024830624787\n",
      "[[ 0.00000000e+00  0.00000000e+00 -2.78016491e-05]\n",
      " [ 0.00000000e+00  0.00000000e+00 -4.18268516e-03]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00]]\n",
      "0.0044209211445943395\n",
      "[[ 0.00000000e+00  0.00000000e+00 -2.50223899e-05]\n",
      " [ 0.00000000e+00  0.00000000e+00 -3.76455290e-03]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00]]\n",
      "0.004417596918266249\n",
      "[[ 0.00000000e+00  0.00000000e+00 -2.25209661e-05]\n",
      " [ 0.00000000e+00  0.00000000e+00 -3.38822025e-03]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00]]\n",
      "0.004414904100005192\n",
      "[[ 0.00000000e+00  0.00000000e+00 -2.02696032e-05]\n",
      " [ 0.00000000e+00  0.00000000e+00 -3.04950861e-03]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00]]\n",
      "0.0044127227593047285\n",
      "[[ 0.00000000e+00  0.00000000e+00 -1.82433032e-05]\n",
      " [ 0.00000000e+00  0.00000000e+00 -2.74465709e-03]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00]]\n",
      "0.004410955745421778\n",
      "[[ 0.00000000e+00  0.00000000e+00 -1.64195672e-05]\n",
      " [ 0.00000000e+00  0.00000000e+00 -2.47028080e-03]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00]]\n",
      "0.004409524360557488\n",
      "[[ 0.00000000e+00  0.00000000e+00 -1.47781454e-05]\n",
      " [ 0.00000000e+00  0.00000000e+00 -2.22333319e-03]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00]]\n",
      "0.004408364854879854\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.00000000e+00  0.00000000e+00 -1.33008123e-05]\n",
      " [ 0.00000000e+00  0.00000000e+00 -2.00107231e-03]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00]]\n",
      "0.004407425587286635\n",
      "[[ 0.00000000e+00  0.00000000e+00 -1.19711644e-05]\n",
      " [ 0.00000000e+00  0.00000000e+00 -1.80103027e-03]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00]]\n",
      "0.004406664725456721\n",
      "[[ 0.00000000e+00  0.00000000e+00 -1.07744379e-05]\n",
      " [ 0.00000000e+00  0.00000000e+00 -1.62098591e-03]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00]]\n",
      "0.004406048382756937\n",
      "[[ 0.00000000e+00  0.00000000e+00 -9.69734514e-06]\n",
      " [ 0.00000000e+00  0.00000000e+00 -1.45894013e-03]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00]]\n",
      "0.004405549109027291\n",
      "[[ 0.00000000e+00  0.00000000e+00 -8.72792654e-06]\n",
      " [ 0.00000000e+00  0.00000000e+00 -1.31309364e-03]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00]]\n",
      "0.004405144668028465\n",
      "[[ 0.00000000e+00  0.00000000e+00 -7.85541822e-06]\n",
      " [ 0.00000000e+00  0.00000000e+00 -1.18182706e-03]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00]]\n",
      "0.004404817047102667\n",
      "[[ 0.00000000e+00  0.00000000e+00 -7.07013231e-06]\n",
      " [ 0.00000000e+00  0.00000000e+00 -1.06368285e-03]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00]]\n",
      "0.004404551654940824\n",
      "[[ 0.00000000e+00  0.00000000e+00 -6.36334941e-06]\n",
      " [ 0.00000000e+00  0.00000000e+00 -9.57349220e-04]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00]]\n",
      "0.004404336671726922\n",
      "[[ 0.00000000e+00  0.00000000e+00 -5.72722177e-06]\n",
      " [ 0.00000000e+00  0.00000000e+00 -8.61645486e-04]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00]]\n",
      "0.004404162522716878\n",
      "[[ 0.00000000e+00  0.00000000e+00 -5.15468617e-06]\n",
      " [ 0.00000000e+00  0.00000000e+00 -7.75509008e-04]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00]]\n",
      "0.004404021451806496\n",
      "[[ 0.00000000e+00  0.00000000e+00 -4.63938548e-06]\n",
      " [ 0.00000000e+00  0.00000000e+00 -6.97983372e-04]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00]]\n",
      "0.00440390717609658\n",
      "[[ 0.00000000e+00  0.00000000e+00 -4.17559807e-06]\n",
      " [ 0.00000000e+00  0.00000000e+00 -6.28207773e-04]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00]]\n",
      "0.0044038146060703266\n",
      "[[ 0.00000000e+00  0.00000000e+00 -3.75817430e-06]\n",
      " [ 0.00000000e+00  0.00000000e+00 -5.65407461e-04]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00]]\n",
      "0.004403739618920679\n",
      "[[ 0.00000000e+00  0.00000000e+00 -3.38247930e-06]\n",
      " [ 0.00000000e+00  0.00000000e+00 -5.08885135e-04]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00]]\n",
      "0.004403678874932161\n",
      "[[ 0.00000000e+00  0.00000000e+00 -3.04434156e-06]\n",
      " [ 0.00000000e+00  0.00000000e+00 -4.58013200e-04]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00]]\n",
      "0.0044036296687393894\n",
      "[[ 0.00000000e+00  0.00000000e+00 -2.74000658e-06]\n",
      " [ 0.00000000e+00  0.00000000e+00 -4.12226801e-04]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00]]\n",
      "0.004403589808837747\n",
      "[[ 0.00000000e+00  0.00000000e+00 -2.46609519e-06]\n",
      " [ 0.00000000e+00  0.00000000e+00 -3.71017550e-04]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00]]\n",
      "0.004403557519980001\n",
      "[[ 0.00000000e+00  0.00000000e+00 -2.21956601e-06]\n",
      " [ 0.00000000e+00  0.00000000e+00 -3.33927882e-04]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00]]\n",
      "0.004403531364111784\n",
      "[[ 0.00000000e+00  0.00000000e+00 -1.99768172e-06]\n",
      " [ 0.00000000e+00  0.00000000e+00 -3.00545972e-04]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00]]\n",
      "0.004403510176324727\n",
      "[[ 0.00000000e+00  0.00000000e+00 -1.79797862e-06]\n",
      " [ 0.00000000e+00  0.00000000e+00 -2.70501166e-04]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00]]\n",
      "0.004403493012974743\n",
      "[[ 0.00000000e+00  0.00000000e+00 -1.61823934e-06]\n",
      " [ 0.00000000e+00  0.00000000e+00 -2.43459862e-04]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00]]\n",
      "0.0044034791096547845\n",
      "[[ 0.00000000e+00  0.00000000e+00 -1.45646812e-06]\n",
      " [ 0.00000000e+00  0.00000000e+00 -2.19121807e-04]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00]]\n",
      "0.004403467847150313\n",
      "[[ 0.00000000e+00  0.00000000e+00 -1.31086876e-06]\n",
      " [ 0.00000000e+00  0.00000000e+00 -1.97216765e-04]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00]]\n",
      "0.004403458723861252\n",
      "[[ 0.00000000e+00  0.00000000e+00 -1.17982459e-06]\n",
      " [ 0.00000000e+00  0.00000000e+00 -1.77501513e-04]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00]]\n",
      "0.004403451333462111\n",
      "[[ 0.00000000e+00  0.00000000e+00 -1.06188056e-06]\n",
      " [ 0.00000000e+00  0.00000000e+00 -1.59757144e-04]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00]]\n",
      "0.004403445346805435\n",
      "[[ 0.00000000e+00  0.00000000e+00 -9.55727101e-07]\n",
      " [ 0.00000000e+00  0.00000000e+00 -1.43786634e-04]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00]]\n",
      "0.004403440497262459\n",
      "[[ 0.00000000e+00  0.00000000e+00 -8.60185527e-07]\n",
      " [ 0.00000000e+00  0.00000000e+00 -1.29412655e-04]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00]]\n",
      "0.004403436568848271\n",
      "[[ 0.00000000e+00  0.00000000e+00 -7.74194997e-07]\n",
      " [ 0.00000000e+00  0.00000000e+00 -1.16475606e-04]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00]]\n",
      "0.004403433386602408\n",
      "[[ 0.00000000e+00  0.00000000e+00 -6.96800718e-07]\n",
      " [ 0.00000000e+00  0.00000000e+00 -1.04831840e-04]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00]]\n",
      "0.0044034308087966545\n",
      "[[ 0.00000000e+00  0.00000000e+00 -6.27143346e-07]\n",
      " [ 0.00000000e+00  0.00000000e+00 -9.43520708e-05]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00]]\n",
      "0.0044034287206228305\n",
      "[[ 0.00000000e+00  0.00000000e+00 -5.64449442e-07]\n",
      " [ 0.00000000e+00  0.00000000e+00 -8.49199375e-05]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00]]\n",
      "0.004403427029079572\n",
      "[[ 0.00000000e+00  0.00000000e+00 -5.08022886e-07]\n",
      " [ 0.00000000e+00  0.00000000e+00 -7.64307102e-05]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00]]\n",
      "0.00440342565883035\n",
      "[[ 0.00000000e+00  0.00000000e+00 -4.57237149e-07]\n",
      " [ 0.00000000e+00  0.00000000e+00 -6.87901291e-05]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00]]\n",
      "0.00440342454884812\n",
      "[[ 0.00000000e+00  0.00000000e+00 -4.11528330e-07]\n",
      " [ 0.00000000e+00  0.00000000e+00 -6.19133572e-05]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00]]\n",
      "0.004403423649697435\n",
      "[[ 0.00000000e+00  0.00000000e+00 -3.70388903e-07]\n",
      " [ 0.00000000e+00  0.00000000e+00 -5.57240385e-05]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00]]\n",
      "0.00440342292133264\n",
      "[[ 0.00000000e+00  0.00000000e+00 -3.33362079e-07]\n",
      " [ 0.00000000e+00  0.00000000e+00 -5.01534500e-05]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00]]\n",
      "0.004403422331314446\n",
      "[[ 0.00000000e+00  0.00000000e+00 -3.00036731e-07]\n",
      " [ 0.00000000e+00  0.00000000e+00 -4.51397389e-05]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00]]\n",
      "0.004403421853365116\n",
      "[[ 0.00000000e+00  0.00000000e+00 -2.70042833e-07]\n",
      " [ 0.00000000e+00  0.00000000e+00 -4.06272355e-05]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00]]\n",
      "0.0044034214661981255\n",
      "[[ 0.00000000e+00  0.00000000e+00 -2.43047347e-07]\n",
      " [ 0.00000000e+00  0.00000000e+00 -3.65658355e-05]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00]]\n",
      "0.004403421152570163\n",
      "[[ 0.00000000e+00  0.00000000e+00 -2.18750530e-07]\n",
      " [ 0.00000000e+00  0.00000000e+00 -3.29104432e-05]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00]]\n",
      "0.004403420898513123\n",
      "[[ 0.00000000e+00  0.00000000e+00 -1.96882604e-07]\n",
      " [ 0.00000000e+00  0.00000000e+00 -2.96204710e-05]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00]]\n",
      "0.004403420692712019\n",
      "[[0.         0.         0.50125104]\n",
      " [0.         0.         2.00372127]\n",
      " [0.         0.         0.        ]]\n"
     ]
    }
   ],
   "source": [
    "# Estimated slope and intercept are present in the weights of the trained network\n",
    "errs = linear.train(train_lin_x, train_lin_y, delay=1, epochs=100, learning_rate=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x23f077b34e0>]"
      ]
     },
     "execution_count": 290,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Seems to work decently well\n",
    "plt.plot(errs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing a regular NN as a graph\n",
    "xor_net = GraphNet(6)\n",
    "xor_net.define_input([0,1])\n",
    "xor_net.connect(0,3)\n",
    "xor_net.connect(0,4)\n",
    "xor_net.connect(1,3)\n",
    "xor_net.connect(1,4)\n",
    "xor_net.connect(2,3)\n",
    "xor_net.connect(2,4)\n",
    "xor_net.connect(2,5)\n",
    "xor_net.connect(3,5)\n",
    "xor_net.connect(4,5)\n",
    "xor_net.activation(2, 'bias')\n",
    "xor_net.activations([3,4,5], 'sigma')\n",
    "xor_net.init_random()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.          0.         -0.         -2.22412709 -5.33522467  0.        ]\n",
      " [-0.          0.         -0.         -0.33988374  0.12345848 -0.        ]\n",
      " [ 0.          0.         -0.          1.33064511 -0.54913868 -0.01966088]\n",
      " [ 0.          0.         -0.         -0.          0.         -0.06524146]\n",
      " [-0.         -0.          0.          0.         -0.          0.26703686]\n",
      " [ 0.         -0.          0.          0.         -0.         -0.        ]]\n"
     ]
    }
   ],
   "source": [
    "train_x = [[0,0], [0,1], [1,0], [1,1]]\n",
    "train_y = [[0], [1], [1], [0]]\n",
    "errs_xor = xor_net.train(train_x, train_y, delay=2, epochs=5000, learning_rate=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x23f0796a0f0>]"
      ]
     },
     "execution_count": 314,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(errs_xor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([[ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "         0.        ],\n",
      "       [ 0.        ,  0.        ,  0.        ,  1.33064511, -0.54913868,\n",
      "        -0.01966088],\n",
      "       [ 0.        ,  0.        ,  0.        ,  1.33064511, -0.54913868,\n",
      "         0.02648921]]), array([[0.        , 0.        , 1.        , 0.        , 0.        ,\n",
      "        0.        ],\n",
      "       [0.        , 0.        , 1.        , 0.79094732, 0.36606426,\n",
      "        0.49508494],\n",
      "       [0.        , 0.        , 0.        , 0.79094732, 0.36606426,\n",
      "        0.50662192]]))\n",
      "(array([[ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "         0.        ],\n",
      "       [ 0.        ,  0.        ,  0.        ,  0.99076137, -0.42568021,\n",
      "        -0.01966088],\n",
      "       [ 0.        ,  0.        ,  0.        , -1.23336572, -5.76090487,\n",
      "         0.03828439]]), array([[0.        , 1.        , 1.        , 0.        , 0.        ,\n",
      "        0.        ],\n",
      "       [1.        , 1.        , 1.        , 0.72923828, 0.39515833,\n",
      "        0.49508494],\n",
      "       [0.        , 0.        , 0.        , 0.22559289, 0.00313838,\n",
      "        0.50956993]]))\n",
      "(array([[ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "         0.        ],\n",
      "       [ 0.        ,  0.        ,  0.        , -0.89348199, -5.88436335,\n",
      "        -0.01966088],\n",
      "       [ 0.        ,  0.        ,  0.        ,  1.33064511, -0.54913868,\n",
      "        -0.03786546]]), array([[1.        , 0.        , 1.        , 0.        , 0.        ,\n",
      "        0.        ],\n",
      "       [0.        , 0.        , 1.        , 0.29039179, 0.0027749 ,\n",
      "        0.49508494],\n",
      "       [0.        , 0.        , 0.        , 0.79094732, 0.36606426,\n",
      "        0.49053477]]))\n",
      "(array([[ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "         0.        ],\n",
      "       [ 0.        ,  0.        ,  0.        , -1.23336572, -5.76090487,\n",
      "        -0.01966088],\n",
      "       [ 0.        ,  0.        ,  0.        , -1.23336572, -5.76090487,\n",
      "        -0.03354082]]), array([[1.        , 1.        , 1.        , 0.        , 0.        ,\n",
      "        0.        ],\n",
      "       [1.        , 1.        , 1.        , 0.22559289, 0.00313838,\n",
      "        0.49508494],\n",
      "       [0.        , 0.        , 0.        , 0.22559289, 0.00313838,\n",
      "        0.49161558]]))\n"
     ]
    }
   ],
   "source": [
    "print(xor_net.step([0,0], 2))\n",
    "print(xor_net.step([0,1], 2))\n",
    "print(xor_net.step([1,0], 2))\n",
    "print(xor_net.step([1,1], 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "bpcheck = GraphNet(8)\n",
    "bpcheck.define_input([0,1])\n",
    "bpcheck.define_output([6,7])\n",
    "bpcheck.connect(0,2)\n",
    "bpcheck.connect(1,2)\n",
    "bpcheck.connect_loop([2,3,4,5])\n",
    "bpcheck.connect(4,6)\n",
    "bpcheck.connect(4,7)\n",
    "#bpcheck.init_random()\n",
    "bpcheck.init_uniform()\n",
    "# Square loop with two inputs and outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 455,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       [1., 1.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       [1., 1.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 0.],\n",
       "       [1., 1.]])"
      ]
     },
     "execution_count": 455,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make sure regular stepping works\n",
    "#print(bpcheck.step([0,1]))\n",
    "#print(bpcheck.step([0,0]))\n",
    "#print(bpcheck.step([0,0]))\n",
    "#print(bpcheck.step([0,0]))\n",
    "# Make sure multiple stepping works\n",
    "bpcheck.reset_state()\n",
    "bpcheck.stepn([0,1], 12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 456,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.  0. ]\n",
      " [0.  0. ]\n",
      " [0.  0. ]\n",
      " [0.  0. ]\n",
      " [0.5 0.5]]\n"
     ]
    }
   ],
   "source": [
    "# Make sure the sequence error is correct (MSE)\n",
    "# Delay = 4 because it takes 4 steps to get from the inputs to outputs in this case\n",
    "error_seq = bpcheck.error_sequence([[0,1]], [[1,1], [0,0], [0,0], [0,0], [0.5,0.5]], delay=4)\n",
    "print(error_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 457,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.25, 0.25])"
      ]
     },
     "execution_count": 457,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This is the sequence of errors in each output, so it's 2D.\n",
    "# To get the total error for each ouput, sum over columns:\n",
    "# Then square to get the SSE for each output\n",
    "np.sum(np.asarray(error_seq), axis=0)**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Paths: 2 \t dt: 0\n",
      "Paths: 1 \t dt: 0\n",
      "Paths: 1 \t dt: 0\n",
      "Paths: 1 \t dt: 0\n",
      "Paths: 3 \t dt: 0\n",
      "Paths: 1 \t dt: 0\n",
      "Paths: 1 \t dt: 0\n",
      "Paths: 1 \t dt: 0\n",
      "Paths: 2 \t dt: 1\n",
      "Paths: 1 \t dt: 1\n",
      "Paths: 1 \t dt: 1\n",
      "Paths: 1 \t dt: 1\n",
      "Paths: 3 \t dt: 1\n",
      "Paths: 1 \t dt: 1\n",
      "Paths: 1 \t dt: 1\n",
      "Paths: 2 \t dt: 2\n",
      "Paths: 1 \t dt: 2\n",
      "Paths: 1 \t dt: 2\n",
      "Paths: 1 \t dt: 2\n",
      "Paths: 3 \t dt: 2\n",
      "Paths: 1 \t dt: 2\n",
      "Paths: 2 \t dt: 3\n",
      "Paths: 1 \t dt: 3\n",
      "Paths: 1 \t dt: 3\n",
      "Paths: 1 \t dt: 3\n",
      "Paths: 3 \t dt: 3\n",
      "Paths: 2 \t dt: 4\n",
      "Paths: 1 \t dt: 4\n",
      "Paths: 1 \t dt: 4\n",
      "Paths: 1 \t dt: 4\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. ],\n",
       "       [0. , 0. , 0. , 0. , 0. , 0. , 0. , 0. ],\n",
       "       [0. , 1. , 0. , 0. , 0. , 1. , 0. , 0. ],\n",
       "       [0. , 0. , 2. , 0. , 0. , 0. , 0. , 0. ],\n",
       "       [0. , 0. , 0. , 2. , 0. , 0. , 0. , 0. ],\n",
       "       [0. , 0. , 0. , 0. , 1. , 0. , 0. , 0. ],\n",
       "       [0. , 0. , 0. , 0. , 0.5, 0. , 0. , 0. ],\n",
       "       [0. , 0. , 0. , 0. , 0.5, 0. , 0. , 0. ]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bpcheck.backprop([[0,1]], [[1,1], [0,0], [0,0], [0,0], [0.5,0.5]], delay=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 459,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.    0.    0.    0.    0.    0.    0.    0.   ]\n",
      " [0.    0.    0.    0.    0.    0.    0.    0.   ]\n",
      " [1.    1.117 0.    0.    0.    0.77  0.    0.   ]\n",
      " [0.    0.    0.919 0.    0.    0.    0.    0.   ]\n",
      " [0.    0.    0.    0.919 0.    0.    0.    0.   ]\n",
      " [0.    0.    0.    0.    0.77  0.    0.    0.   ]\n",
      " [0.    0.    0.    0.    1.06  0.    0.    0.   ]\n",
      " [0.    0.    0.    0.    1.06  0.    0.    0.   ]]\n"
     ]
    }
   ],
   "source": [
    "train_x = [[[0,1]]]\n",
    "train_y = [[[1,1], [0,0], [0,0], [0,0], [0.5,0.5]]]\n",
    "errs_bpc = bpcheck.train(train_x, train_y, delay=4, epochs=200, learning_rate=0.05, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 460,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x2749b6d2f60>,\n",
       " <matplotlib.lines.Line2D at 0x2749b6db0f0>]"
      ]
     },
     "execution_count": 460,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(errs_bpc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 461,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.  , 0.  ],\n",
       "       [0.  , 0.  ],\n",
       "       [0.  , 0.  ],\n",
       "       [1.  , 1.  ],\n",
       "       [0.  , 0.  ],\n",
       "       [0.  , 0.  ],\n",
       "       [0.  , 0.  ],\n",
       "       [0.5 , 0.5 ],\n",
       "       [0.  , 0.  ],\n",
       "       [0.  , 0.  ],\n",
       "       [0.  , 0.  ],\n",
       "       [0.25, 0.25]])"
      ]
     },
     "execution_count": 461,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Trained perfectly\n",
    "bpcheck.stepn([0,1], 12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "fc = GraphNet(7)\n",
    "fc.connect(0,1)\n",
    "fc.connect_complete([1,2,3,4,5])\n",
    "fc.connect(5,6)\n",
    "#fc.activation(6, 'sigma')\n",
    "fc.init_markov()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x23541503d68>]"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(fc.stepn([1], 20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Paths: 1 \t dt: 0 \t k: 1\n",
      "Paths: 1 \t dt: 0 \t k: 2\n",
      "Paths: 4 \t dt: 0 \t k: 3\n",
      "Paths: 6 \t dt: 0 \t k: 4\n",
      "Paths: 6 \t dt: 0 \t k: 5\n",
      "Paths: 6 \t dt: 0 \t k: 6\n",
      "Paths: 6 \t dt: 0 \t k: 7\n",
      "Paths: 6 \t dt: 0 \t k: 8\n",
      "Paths: 6 \t dt: 0 \t k: 9\n",
      "Paths: 6 \t dt: 0 \t k: 10\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [-0.01140735,  0.        , -0.02167184, -0.01344835, -0.01634691,\n",
       "        -0.01744676,  0.        ],\n",
       "       [ 0.        , -0.01949004,  0.        , -0.01186621, -0.01449547,\n",
       "        -0.01564276,  0.        ],\n",
       "       [ 0.        , -0.01933187, -0.01912275,  0.        , -0.01435964,\n",
       "        -0.01548467,  0.        ],\n",
       "       [ 0.        , -0.02045152, -0.02160227, -0.01338299,  0.        ,\n",
       "        -0.01741117,  0.        ],\n",
       "       [ 0.        , -0.02486348, -0.031032  , -0.02003848, -0.02399847,\n",
       "         0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        -0.18137725,  0.        ]])"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fc.backprop([[1]], [[1]], delay=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
