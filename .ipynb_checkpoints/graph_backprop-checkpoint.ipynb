{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GraphNet:\n",
    "    # Make an empty graph on n nodes with linear activation\n",
    "    def __init__(self, n):\n",
    "        self.size = n\n",
    "        self.adj = np.zeros((n, n))\n",
    "        self.weights = np.zeros((n, n))\n",
    "        self.act = ['linear' for i in range(self.size)]\n",
    "        self.input_nodes = []\n",
    "        self.output_nodes = []\n",
    "        self.tempstates = [[0 for i in range(self.size)]]\n",
    "        self.states = [[0 for i in range(self.size)]]\n",
    "        self.mode = 'overwrite'\n",
    "        self.time = 0\n",
    "    \n",
    "    # Sets the mode for the step method\n",
    "    # Options: overwrite, add\n",
    "    def mode(self, m):\n",
    "        self.mode = m\n",
    "    \n",
    "    # Connect an edge from node i to node j\n",
    "    def connect(self, i, j, w=1):\n",
    "        self.adj[j,i] = w\n",
    "    \n",
    "    # Change activation on node i\n",
    "    # Options: linear, relu, sigmoid/logistic, tanh\n",
    "    def activation(self, i, f):\n",
    "        self.act[i] = f\n",
    "    \n",
    "    # Get the list of edge weights that are inputs to node i\n",
    "    def inputs(self, i):\n",
    "        ins = []\n",
    "        for k in range(self.size):\n",
    "            if self.adj[i,k] != 0:\n",
    "                ins.append(k)\n",
    "        return ins\n",
    "        #return np.ndarray.tolist(np.ndarray.astype(self.adj[i,:], int))\n",
    "    \n",
    "    # Get the list of edge weights that are outputs from node i\n",
    "    def outputs(self, i):\n",
    "        outs = []\n",
    "        for k in range(self.size):\n",
    "            if self.adj[k,i] != 0:\n",
    "                outs.append(k)\n",
    "        return outs\n",
    "        #return np.ndarray.tolist(np.ndarray.astype(self.adj[:,i], int))\n",
    "    \n",
    "    # Reset weights\n",
    "    def reset_weights(self):\n",
    "        self.weights = np.copy(self.adj)\n",
    "    \n",
    "    # Initialize random edge weights, assuming edge weights are all 0 or 1\n",
    "    def init_random(self):\n",
    "        self.weights = np.random.rand(self.size, self.size)*self.adj\n",
    "    \n",
    "    # Normalize columns to satisfy Markov state transition rules\n",
    "    def init_markov(self):\n",
    "        self.init_random()\n",
    "        for i in range(self.size):\n",
    "            colsum = sum(self.weights[:,i])\n",
    "            if colsum != 0:\n",
    "                for j in range(self.size):\n",
    "                    self.weights[j,i] /= colsum\n",
    "    \n",
    "    # Make the vector of indices be the input nodes\n",
    "    def define_input(self, v):\n",
    "        self.input_nodes = v\n",
    "    \n",
    "    # Make the vector of indices be the output nodes\n",
    "    def define_output(self, v):\n",
    "        self.output_nodes = v\n",
    "    \n",
    "    # Reset state\n",
    "    def reset_state(self):\n",
    "        self.states = [[0 for i in range(self.size)]]\n",
    "        self.tempstates = [[0 for i in range(self.size)]]\n",
    "    \n",
    "    # Runs one time step of the network, with the given input values, and returns the current output values\n",
    "    def step(self, input_vals):\n",
    "        self.time += 1\n",
    "        # tempstate = [self.states[-1][i] for i in range(self.size)]\n",
    "        # Edit the inputs of the last state. This will make things consistent, so each step is a single state\n",
    "        if self.mode == 'overwrite':\n",
    "            for i in range(len(self.input_nodes)):\n",
    "                self.states[-1][self.input_nodes[i]] = input_vals[i]\n",
    "        if self.mode == 'add':\n",
    "            for i in range(len(self.input_nodes)):\n",
    "                self.states[-1][self.input_nodes[i]] += input_vals[i]\n",
    "        # Weighted sum of inputs\n",
    "        tempstate = np.dot(self.weights, self.states[-1])\n",
    "        # Apply activation functions\n",
    "        state = [tempstate[i] for i in range(self.size)]\n",
    "        for i in range(self.size):\n",
    "            #if self.act[i] == 'linear':\n",
    "            #    do nothing\n",
    "            if self.act[i] == 'relu':\n",
    "                state[i] = state[i] if state[i] > 0 else 0\n",
    "            if self.act[i] == 'sigmoid' or self.act[i] == 'logistic':\n",
    "                state[i] = 1.0/(1.0+exp(-state[i]))\n",
    "            if self.act[i] == 'tanh':\n",
    "                state[i] = (exp(2*state[i]) - 1)/(exp(2*state[i]) + 1)\n",
    "        output_vals = [state[self.output_nodes[i]] for i in range(len(self.output_nodes))]\n",
    "        self.tempstates.append(tempstate)\n",
    "        self.states.append(state)\n",
    "        return output_vals\n",
    "    \n",
    "    # Runs several time steps of the network, with the given vector of input value vectors at each time step, \n",
    "    # and returns a vector of output values\n",
    "    def steps(self, input_vals_v, n=0):\n",
    "        output_vals_v = []\n",
    "        empty_input = [0 for i in range(len(self.input_nodes))]\n",
    "        for t in range(max(n, len(input_vals_v))):\n",
    "            input_vals = empty_input\n",
    "            if t < len(input_vals_v):\n",
    "                input_vals = input_vals_v[t]\n",
    "            output_vals_v.append(self.step(input_vals))\n",
    "        return output_vals_v\n",
    "    \n",
    "    # Run n steps on a input only at initial step\n",
    "    def stepn(self, input_vals_0, n=1):\n",
    "        output_vals_v = []\n",
    "        empty_input = [0 for i in range(len(self.input_nodes))]\n",
    "        for t in range(n):\n",
    "            input_vals = empty_input\n",
    "            if t == 0:\n",
    "                input_vals = input_vals_0\n",
    "            output_vals_v.append(self.step(input_vals))\n",
    "        return output_vals_v\n",
    "    \n",
    "    # Waits until the first nonzero output value and uses that as the real output\n",
    "    def error_first(self, train_vals, label_vals, max_step=100):\n",
    "        self.reset_state()\n",
    "        output_vals = [0 for i in range(len(self.output_nodes))]\n",
    "        empty_input = [0 for i in range(len(self.input_nodes))]\n",
    "        t = 0\n",
    "        while t < max_step and np.count_nonzero(output_vals) == 0:\n",
    "            input_vals = empty_input\n",
    "            if t == 0:\n",
    "                input_vals = train_vals\n",
    "            output_vals = self.step(input_vals)\n",
    "            t += 1\n",
    "        err_v = np.subtract(output_vals, label_vals)\n",
    "        return err_v\n",
    "    \n",
    "    # Waits a fixed delay\n",
    "    def error_delay(self, train_vals, label_vals, delay, reset=True, max_step=100):\n",
    "        if reset:\n",
    "            self.reset_state()\n",
    "        output_vals = [0 for i in range(len(self.output_nodes))]\n",
    "        empty_input = [0 for i in range(len(self.input_nodes))]\n",
    "        t = 0\n",
    "        while t < delay:\n",
    "            input_vals = empty_input\n",
    "            if t == 0:\n",
    "                input_vals = train_vals\n",
    "            output_vals = self.step(input_vals)\n",
    "            t += 1\n",
    "        err_v = np.subtract(output_vals, label_vals)\n",
    "        return err_v\n",
    "    \n",
    "    # Mean square error of training batch. train_x and train_y are batches of training data\n",
    "    # Data type options: 1_to_1...\n",
    "    # If delay = 0, first nonzero output will be used, otherwise there will be a fixed delay before the output is sampled\n",
    "    def mse_batch(self, train_x, train_y, data_type='1_to_1', delay=0, reset=True, max_step=100):\n",
    "        mse = 0\n",
    "        for k in range(len(train_x)):\n",
    "            if data_type == '1_to_1':\n",
    "                if delay == 0:\n",
    "                    mse += sum(self.error_first(train_x[k], train_y[k], max_step)**2)\n",
    "                else:\n",
    "                    mse += sum(self.error_delay(train_x[k], train_y[k], delay, reset, max_step)**2)\n",
    "        mse /= 2*len(train_x) # Factor of 1/2 for the coefficient of 2 on the derivative to cancel, as usual...\n",
    "        return mse\n",
    "    \n",
    "    def backprop(self, train_vals, label_vals, delay):\n",
    "        dw = np.zeros((self.size, self.size))\n",
    "        # E = 1/2 (observed - expected)**2\n",
    "        err_v = self.error_delay(train_vals, label_vals, delay)\n",
    "        nodes_i = [self.output_nodes[i] for i in range(len(self.output_nodes))]\n",
    "        nodes_d = [err_v[i] for i in range(len(self.output_nodes))]\n",
    "        newnodes_i = []\n",
    "        newnodes_d = []\n",
    "        # dE/dw = (observed - expected) * d(observed)/dw\n",
    "        for k in range(1, len(self.states)): # Or max step size, maybe? \n",
    "            for i in range(len(nodes_i)):\n",
    "                # node value = activation( weighted sum of input values )\n",
    "                # d node value / dw = activation'( weighted sum of input values ) * d (weighted sum of input values) / dw\n",
    "                node_val = self.states[len(self.states)-k][nodes_i[i]]\n",
    "                node_sum = self.tempstates[len(self.states)-k][nodes_i[i]]\n",
    "                act_deriv = 1\n",
    "                #if self.act[nodes_i[i]] == 'linear':\n",
    "                #    do nothing\n",
    "                if self.act[nodes_i[i]] == 'relu' and node_sum < 0:\n",
    "                    act_deriv = 0\n",
    "                if self.act[nodes_i[i]] == 'sigmoid' or self.act[nodes_i[i]] == 'logistic':\n",
    "                    act_deriv = node_val * (1 - node_val)\n",
    "                if self.act[nodes_i[i]] == 'tanh':\n",
    "                    act_deriv = 4.0/(exp(node_sum)+exp(-node_sum))**2\n",
    "                in_nodes_i = self.inputs(nodes_i[i])\n",
    "                for j in range(len(in_nodes_i)):\n",
    "                    # Self-weights are covered just fine when nodes_i[i] = in_nodes_i[j]\n",
    "                    in_node_val = self.states[len(self.states)-(k+1)][in_nodes_i[j]]\n",
    "                    # d (weighted sum of input values) / dw = input value [...for w in these weights]\n",
    "                    dweight = nodes_d[i] * act_deriv * in_node_val\n",
    "                    # Add this to the total derivative with respect to this weight\n",
    "                    dw[nodes_i[i], in_nodes_i[j]] += dweight\n",
    "                    print(in_node_val)\n",
    "                    print(dw)\n",
    "                    # nodes_d stores the buildup of chained derivatives\n",
    "                    weight = self.weights[nodes_i[i], in_nodes_i[j]]\n",
    "                    # d (weighted sum of input values) / dw = ... * weight * d node value / dw\n",
    "                    if in_nodes_i[j] in newnodes_i:\n",
    "                        newnodes_d[in_nodes_i[j]] += nodes_d[i] * act_deriv * weight\n",
    "                    else:\n",
    "                        newnodes_i.append(in_nodes_i[j])\n",
    "                        newnodes_d.append( nodes_d[i] * act_deriv * weight )\n",
    "            nodes_i = newnodes_i\n",
    "            nodes_d = newnodes_d\n",
    "            newnodes_i = []\n",
    "            newnodes_d = []\n",
    "        return dw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = GraphNet(4)\n",
    "test.connect(0,1)\n",
    "test.connect(1,2)\n",
    "test.connect(2,1)\n",
    "test.connect(2,3)\n",
    "test.define_input([0])\n",
    "test.define_output([3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.        , 0.        , 0.        ],\n",
       "       [1.        , 0.        , 0.41474401, 0.        ],\n",
       "       [0.        , 1.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.58525599, 0.        ]])"
      ]
     },
     "execution_count": 341,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.adj\n",
    "test.init_markov()\n",
    "test.weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0.0],\n",
       " [0.0],\n",
       " [0.44203492419103935],\n",
       " [0.0],\n",
       " [0.2466400499864614],\n",
       " [0.0],\n",
       " [0.13761653418822178],\n",
       " [0.0],\n",
       " [0.07678521993089758],\n",
       " [0.0]]"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.stepn([1], 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0.0],\n",
       " [0.0],\n",
       " [0.44203492419103935],\n",
       " [0.22101746209551967],\n",
       " [0.35714878103422126],\n",
       " [0.17857439051711063],\n",
       " [0.19927654668483713],\n",
       " [0.09963827334241857],\n",
       " [0.11118935347795303],\n",
       " [0.055594676738976515]]"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.reset_state()\n",
    "test.steps([[1],[0.5],[0.25],[0.125]], 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3423384182578477"
      ]
     },
     "execution_count": 287,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x = [[1]]\n",
    "train_y = [[1]]\n",
    "test.mse_batch(train_x, train_y, delay=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.41474400636523623\n",
      "[[ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.         -0.31407261  0.        ]]\n",
      "0.41474400636523623\n",
      "[[ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.         -0.18381288  0.          0.        ]\n",
      " [ 0.          0.         -0.31407261  0.        ]]\n",
      "0\n",
      "[[ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.        ]\n",
      " [ 0.         -0.18381288  0.          0.        ]\n",
      " [ 0.          0.         -0.31407261  0.        ]]\n",
      "1.0\n",
      "[[ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.         -0.44319598  0.        ]\n",
      " [ 0.         -0.18381288  0.          0.        ]\n",
      " [ 0.          0.         -0.31407261  0.        ]]\n",
      "1.0\n",
      "[[ 0.          0.          0.          0.        ]\n",
      " [ 0.          0.         -0.44319598  0.        ]\n",
      " [ 0.         -0.36762575  0.          0.        ]\n",
      " [ 0.          0.         -0.31407261  0.        ]]\n",
      "1\n",
      "[[ 0.          0.          0.          0.        ]\n",
      " [-0.18381288  0.         -0.44319598  0.        ]\n",
      " [ 0.         -0.36762575  0.          0.        ]\n",
      " [ 0.          0.         -0.31407261  0.        ]]\n",
      "0\n",
      "[[ 0.          0.          0.          0.        ]\n",
      " [-0.18381288  0.         -0.44319598  0.        ]\n",
      " [ 0.         -0.36762575  0.          0.        ]\n",
      " [ 0.          0.         -0.31407261  0.        ]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 0.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [-0.18381288,  0.        , -0.44319598,  0.        ],\n",
       "       [ 0.        , -0.36762575,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        , -0.31407261,  0.        ]])"
      ]
     },
     "execution_count": 345,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.backprop([1], [1], 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, 0, 0, 0],\n",
       " [0, 1.0, 0.0, 0.0],\n",
       " [0, 0.0, 1.0, 0.0],\n",
       " [0, 0.41474400636523623, 0.0, 0.5852559936347638],\n",
       " [0, 0.0, 0.41474400636523623, 0.0],\n",
       " [0.0, 0.1720125908158871, 0.0, 0.24273141554934913]]"
      ]
     },
     "execution_count": 346,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.error_delay([1], [1], 5)\n",
    "test.states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
